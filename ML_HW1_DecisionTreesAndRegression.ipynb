{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/c-daly/Notebooks/blob/main/ML_HW1_DecisionTreesAndRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lH1avDQgkq-5"
      },
      "source": [
        "# CS 6140 Machine Learning: Assignment - 1 (Total Points: 100)\n",
        "## Prof. Ahmad Uzair "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just some high level imports."
      ],
      "metadata": {
        "id": "q_VV5lrAzYEJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_MpuTeDMVQ73"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn import tree\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PFpvDelkq-6"
      },
      "source": [
        "### Q1. Decision Tree Classifier (50 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JX03ez5ckq-7"
      },
      "source": [
        "### Q1.1 Growing Decison Trees from scratch (40 points)\n",
        "\n",
        "Decision Trees (DTs) are a non-parametric supervised learning method used for classification and regression. The goal of this question in the assignment is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features. \n",
        "You must also print the Decision Tree. Use information gain based on entropy as the splitting measure. \n",
        "\n",
        "Use the data.csv dataset for this particular question. The dataset should be uploaded on Canvas with Assignment 1. Split the dataset into training and test data and calculate testing accuracy.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just setting some helpful constants and splitting the data."
      ],
      "metadata": {
        "id": "ZnEwT9q4LD-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FALSE = 0\n",
        "TRUE = 1\n",
        "\n",
        "CLASS_0 = 0\n",
        "CLASS_1 = 1\n",
        "CLASS_2 = 2\n",
        "LABEL_VALUES = [CLASS_0, CLASS_1, CLASS_2]\n",
        "LABEL_COLUMN = 'class'\n",
        "\n",
        "PLURALITY = 'Plurality'\n",
        "UNANIMOUS = 'Unanimous'\n",
        "DECISION_TYPES = [PLURALITY, UNANIMOUS]\n",
        "\n",
        "# read and split the data\n",
        "df = pd.read_csv('data.csv')\n",
        "train_df, test_df = train_test_split(df, test_size=0.2)"
      ],
      "metadata": {
        "id": "xYs1m8MyJkxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data structures to implement the decision tree."
      ],
      "metadata": {
        "id": "4xpa_YGBLHpO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Main element of the decision tree\n",
        "class Node:\n",
        "  def __init__(self, attribute, value):\n",
        "    self.attribute = attribute\n",
        "    self.value = value\n",
        "    self.children = []\n",
        "\n",
        "class DecisionTree:\n",
        "  def __init__(self, node):\n",
        "    self.node = node\n",
        "    self.root = node\n",
        "  \n",
        "  # uses existing tree to classify new example\n",
        "  def classify(self, example):\n",
        "    iteration = 0\n",
        "    node = self.node\n",
        "\n",
        "    while True:\n",
        "      if node.value in DECISION_TYPES:\n",
        "        return node.attribute\n",
        "      elif example[node.attribute] < node.value:\n",
        "        node = node.children[TRUE]\n",
        "      elif len(node.children) > 1:\n",
        "        node = node.children[FALSE]\n",
        "      else:\n",
        "        print(f\"{node.attribute}\")\n",
        "        return node.attribute"
      ],
      "metadata": {
        "id": "BVtzXbmHLIJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These are the functions that do most of the work."
      ],
      "metadata": {
        "id": "pTCP-jYuL77S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Entropy calculation based on frequency of class labels.\n",
        "#\n",
        "# examples: dataset on which to calculate entropy\n",
        "def calculateEntropy(examples):\n",
        "  label = examples[LABEL_COLUMN]\n",
        "  _, counts = np.unique(label, return_counts=True)\n",
        "  probabilities = counts/counts.sum()\n",
        "  entropy = sum(probabilities * -np.log2(probabilities))\n",
        "  return entropy\n",
        "\n",
        "# Entropy calculation for the children\n",
        "#\n",
        "# lt_examples: dataset of values less than the threshold\n",
        "# gte_examples: dataset of values greater than or equal \n",
        "#               to the threshold\n",
        "# returns: a float representing the average entropy of the children\n",
        "def calculateRemainder(lt_examples, gte_examples):\n",
        "  total_len = len(lt_examples) + len(gte_examples)\n",
        "  lt_entropy = calculateEntropy(lt_examples)\n",
        "  gte_entropy = calculateEntropy(gte_examples)\n",
        "\n",
        "  remainder = len(lt_examples)/total_len * lt_entropy + len(gte_examples)/total_len * gte_entropy\n",
        "  return remainder\n",
        "\n",
        "# Remove a feature/column from a dataset\n",
        "#\n",
        "# examples: dataset to drop column from\n",
        "# feature: feature/column to drop\n",
        "def dropFeatureColumn(examples, feature):\n",
        "  return examples.drop([feature], axis=1)\n",
        "\n",
        "# Split a given dataset on feature < val\n",
        "# into two separate datasets, lt and gte\n",
        "#\n",
        "# examples: dataset to split\n",
        "# feature: feature to split on\n",
        "# val: threshold to use for splitting\n",
        "#\n",
        "# returns: two datasets, one less than and one greater than\n",
        "#          the threshold\n",
        "def splitData(examples, feature, val):\n",
        "  # nothing to split on, return nothing\n",
        "  if feature is None or val is None:\n",
        "    return None, None\n",
        "\n",
        "  lt = examples[(examples[feature] < val)]\n",
        "  gte = examples[(examples[feature] >= val)]\n",
        "\n",
        "  lt = dropFeatureColumn(lt, feature)\n",
        "  gte = dropFeatureColumn(gte, feature)\n",
        "\n",
        "  return lt, gte\n",
        "\n",
        "# get all the values in a column\n",
        "#\n",
        "# examples: dataset from which to fetch examples\n",
        "# feature: column/feature to fetch values from\n",
        "def getValuesByFeature(examples, feature):\n",
        "  return examples[feature]\n",
        "\n",
        "# get all examples belonging to class == class_label\n",
        "#\n",
        "# examples: dataset from which to fetch examples\n",
        "# class_label: class we want examples for\n",
        "def getExamplesByClass(examples, class_label):\n",
        "   value_examples = examples[(examples[LABEL_COLUMN] == class_label)]\n",
        "   return value_examples\n",
        "\n",
        "# This method stitches together the entropy calculations\n",
        "# to measure information gain (IG)\n",
        "#\n",
        "# examples: current dataset\n",
        "# feature: current feature/column\n",
        "# value: threshold value for splitting\n",
        "def calculateGainForFeatureAndValue(examples, feature, value):\n",
        "  lt_count = 0\n",
        "  gte_count = 0\n",
        "  lt, gte = splitData(examples, feature, value)\n",
        "  gain = calculateEntropy(examples) - calculateRemainder(lt, gte)\n",
        "  return gain\n",
        "\n",
        "# Determine the best possible spllit for a given dataset\n",
        "# based on information gain.\n",
        "#\n",
        "# examples: current dataset\n",
        "def getBestSplit(examples):\n",
        "  features = examples.columns\n",
        "  gain = 0\n",
        "  split_feature = None\n",
        "  split_value = None\n",
        "  temp_gain = 0\n",
        "  # all features but the class label\n",
        "  for feature in features[:-1]:\n",
        "    values = getValuesByFeature(examples, feature).unique()\n",
        "    # iterate over all possible features for this value\n",
        "    for value in values:\n",
        "      temp_gain = calculateGainForFeatureAndValue(examples, feature, value)\n",
        "      # we've found a better split\n",
        "      if temp_gain > gain:\n",
        "        gain = temp_gain\n",
        "        split_feature = feature\n",
        "        split_value = value\n",
        "  # return the best split\n",
        "  return split_feature, split_value\n",
        "        \n",
        "# get most frequent class for a set of examples\n",
        "#\n",
        "# examples: current dataset\n",
        "#\n",
        "# returns: the most common value in a column\n",
        "def getPluralityValue(examples):\n",
        "  return examples[LABEL_COLUMN].mode()[0]\n",
        "\n",
        "# recursive method that learns a decision tree\n",
        "# for a given dataset using information gain as a metric.\n",
        "#\n",
        "# examples: current dataset\n",
        "# parent_examples: dataset from parent\n",
        "# \n",
        "# returns: An appropriately fromed Node, given the provided data.\n",
        "def learnTree(examples, parent_examples):\n",
        "  # Check all the reasons we might be done\n",
        "  if examples is None or len(examples) == 0:\n",
        "    return Node(getPluralityValue(parent_examples), PLURALITY)\n",
        "  elif len(examples[LABEL_COLUMN].unique()) == 1:\n",
        "    return Node(examples[LABEL_COLUMN].values[0], UNANIMOUS)\n",
        "  elif len(examples.columns) < 2:\n",
        "    return Node(getPluralityValue(examples), PLURALITY)\n",
        "  # We're not done\n",
        "  else:\n",
        "    # We're going find the best split \n",
        "    # and create a node for our current feature/value.\n",
        "    # Recursively invoke learnTree to create child nodes.\n",
        "    feature, val = getBestSplit(examples)\n",
        "    node = Node(feature, val)\n",
        "    lt, gte = splitData(examples, feature, val)\n",
        "    node.children = [None, None]\n",
        "    node.children[TRUE] = learnTree(lt, examples)\n",
        "    node.children[FALSE] = learnTree(gte, examples)\n",
        "    return node"
      ],
      "metadata": {
        "id": "vU6wlC-3L8ZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Printing stuff"
      ],
      "metadata": {
        "id": "yCK4pVyKMWqp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic utility class for printing the decision tree\n",
        "class TreePrinter():\n",
        "  def __init__(self, root):\n",
        "    self.root = root\n",
        "  \n",
        "  # Prints the entire tree.\n",
        "  def printTree(self):\n",
        "    self.printNode(self.root, 1)\n",
        "  \n",
        "  # print the node of a tree. Recursively invokes\n",
        "  # printNode for children.\n",
        "  #\n",
        "  # node: the current node we're printing\n",
        "  # tree_level: how far down the tree are we?\n",
        "  def printNode(self, node, tree_level):\n",
        "    if node.children is not None:\n",
        "      indent_string = '|\\t' * (tree_level - 1)\n",
        "      if len(node.children) == 0:\n",
        "        print(f\"{indent_string}{tree_level}: Leaf with value {node.attribute}, {node.value} decision.\")\n",
        "      else:\n",
        "        print(f\"{indent_string}{tree_level}: {node.attribute} at {node.value}\")\n",
        "      if len(node.children) > 0: # and node.children[TRUE] is not None:\n",
        "        self.printNode(node.children[TRUE], tree_level + 1)\n",
        "      if len(node.children) > 1: # and node.children[FALSE] is not None:\n",
        "        self.printNode(node.children[FALSE], tree_level + 1)\n",
        "\n"
      ],
      "metadata": {
        "id": "DR9qDZ2mMaXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation stuff"
      ],
      "metadata": {
        "id": "515VOVDMMdcX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "node = learnTree(train_df, None)\n",
        "dt = DecisionTree(node)\n",
        "\n",
        "tp = TreePrinter(node)\n",
        "tp.printTree()\n",
        "\n",
        "y_pred = []\n",
        "y_actual = test_df[LABEL_COLUMN].values\n",
        "#for i in range(0,len(test_df)):\n",
        "#  y_pred.append(dt.classify(test_df.iloc[i]))\n",
        "  #print(f\"estimate: {dt.classify(test_df.iloc[i])}, actual: {test_df.iloc[i][LABEL_COLUMN]}\") \n",
        "y_pred = test_df.apply(dt.classify, axis = 1)\n",
        "cm_scratch = confusion_matrix(y_pred, y_actual)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KSee9CnMgOq",
        "outputId": "390107d4-9e88-47ed-8559-c5c6940a7cdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1: feature3 at 3.0\n",
            "|\t2: Leaf with value 0, Unanimous decision.\n",
            "|\t2: feature4 at 1.8\n",
            "|\t|\t3: feature1 at 7.2\n",
            "|\t|\t|\t4: feature2 at 2.3\n",
            "|\t|\t|\t|\t5: Leaf with value 1, Plurality decision.\n",
            "|\t|\t|\t|\t5: Leaf with value 1, Plurality decision.\n",
            "|\t|\t|\t4: Leaf with value 2, Unanimous decision.\n",
            "|\t|\t3: feature1 at 6.0\n",
            "|\t|\t|\t4: feature2 at 3.2\n",
            "|\t|\t|\t|\t5: Leaf with value 2, Unanimous decision.\n",
            "|\t|\t|\t|\t5: Leaf with value 1, Unanimous decision.\n",
            "|\t|\t|\t4: Leaf with value 2, Unanimous decision.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the output above, the node shows what decision was made at a given point.  So, at the root, the algorithm chose to split on feature3 with value 3.3, and the children are the nodes representing the resulting datasets. That initial split was able to classify one branch as class 0, but the other went on to be split on feature 4 at 1.8.\n",
        "\n",
        "Unanimous or Plurality decision indicate whether the classification was made because all elements had the same class (unanimous), or the most frequently occurring (plurality)."
      ],
      "metadata": {
        "id": "jI_WpxzHx_jA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiOjkIIHVG6r"
      },
      "source": [
        "### Q1.2 Decision Tree using Sklearn Library (10 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybrNHZxvVG6r"
      },
      "source": [
        "Use the Decision Tree Classifier from the Sklearn Library and use gini index as a splitting measure. Use the data.csv dataset.\n",
        "Calculate accuracy for this model. \n",
        "Print the Decision tree and compare the Decision Trees generated from your code and Sklearn."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# y is just the label\n",
        "y = train_df['class']\n",
        "test_y = test_df['class']\n",
        "\n",
        "# drop the label from X\n",
        "X = train_df.drop(['class'], axis=1)\n",
        "test_X = test_df.drop(['class'], axis=1)\n",
        "\n",
        "# defaults to gini\n",
        "dt = tree.DecisionTreeClassifier()\n",
        "dt = dt.fit(X,y)\n",
        "\n",
        "# printing\n",
        "y_pred = dt.predict(test_X)\n",
        "cm_sklearn = confusion_matrix(test_y, y_pred)\n",
        "\n",
        "print(f\"{tree.export_text(dt)}\\n\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(f\"{cm_sklearn}\\n\")\n",
        "tree.plot_tree(dt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rcWt3Grvw1PH",
        "outputId": "817e0e3b-e979-44f4-a651-55b9148c9003"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|--- feature_3 <= 0.80\n",
            "|   |--- class: 0\n",
            "|--- feature_3 >  0.80\n",
            "|   |--- feature_2 <= 4.75\n",
            "|   |   |--- class: 1\n",
            "|   |--- feature_2 >  4.75\n",
            "|   |   |--- feature_3 <= 1.75\n",
            "|   |   |   |--- feature_1 <= 2.45\n",
            "|   |   |   |   |--- class: 2\n",
            "|   |   |   |--- feature_1 >  2.45\n",
            "|   |   |   |   |--- feature_2 <= 5.05\n",
            "|   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |--- feature_2 >  5.05\n",
            "|   |   |   |   |   |--- feature_0 <= 6.15\n",
            "|   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |--- feature_0 >  6.15\n",
            "|   |   |   |   |   |   |--- class: 2\n",
            "|   |   |--- feature_3 >  1.75\n",
            "|   |   |   |--- feature_2 <= 4.85\n",
            "|   |   |   |   |--- feature_0 <= 5.95\n",
            "|   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |--- feature_0 >  5.95\n",
            "|   |   |   |   |   |--- class: 2\n",
            "|   |   |   |--- feature_2 >  4.85\n",
            "|   |   |   |   |--- class: 2\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 8  0  0]\n",
            " [ 0 12  0]\n",
            " [ 0  2  8]]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(0.3, 0.9285714285714286, 'X[3] <= 0.8\\ngini = 0.666\\nsamples = 120\\nvalue = [42, 38, 40]'),\n",
              " Text(0.2, 0.7857142857142857, 'gini = 0.0\\nsamples = 42\\nvalue = [42, 0, 0]'),\n",
              " Text(0.4, 0.7857142857142857, 'X[2] <= 4.75\\ngini = 0.5\\nsamples = 78\\nvalue = [0, 38, 40]'),\n",
              " Text(0.3, 0.6428571428571429, 'gini = 0.0\\nsamples = 34\\nvalue = [0, 34, 0]'),\n",
              " Text(0.5, 0.6428571428571429, 'X[3] <= 1.75\\ngini = 0.165\\nsamples = 44\\nvalue = [0, 4, 40]'),\n",
              " Text(0.2, 0.5, 'X[1] <= 2.45\\ngini = 0.5\\nsamples = 6\\nvalue = [0, 3, 3]'),\n",
              " Text(0.1, 0.35714285714285715, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
              " Text(0.3, 0.35714285714285715, 'X[2] <= 5.05\\ngini = 0.48\\nsamples = 5\\nvalue = [0, 3, 2]'),\n",
              " Text(0.2, 0.21428571428571427, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
              " Text(0.4, 0.21428571428571427, 'X[0] <= 6.15\\ngini = 0.444\\nsamples = 3\\nvalue = [0, 1, 2]'),\n",
              " Text(0.3, 0.07142857142857142, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
              " Text(0.5, 0.07142857142857142, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
              " Text(0.8, 0.5, 'X[2] <= 4.85\\ngini = 0.051\\nsamples = 38\\nvalue = [0, 1, 37]'),\n",
              " Text(0.7, 0.35714285714285715, 'X[0] <= 5.95\\ngini = 0.444\\nsamples = 3\\nvalue = [0, 1, 2]'),\n",
              " Text(0.6, 0.21428571428571427, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
              " Text(0.8, 0.21428571428571427, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
              " Text(0.9, 0.35714285714285715, 'gini = 0.0\\nsamples = 35\\nvalue = [0, 0, 35]')]"
            ]
          },
          "metadata": {},
          "execution_count": 322
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAADnCAYAAAC9roUQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOy9fVyVRd74/77EkHNrSLuY4OKzWGKKhSZLrk9Lbm2otOumbmhqcSukX9FEE38huK6CN8hRA7zXh7B1U3Y1uZGM1JR8WMytwFLQUFHBAOXpoCLC4Vy/P4hLj4DydA7nHOb9el2vU3PNzDUzznyY+cxnPiPJsoxAIBAIjEOHti6AQCAQtCeE0BUIBAIjIoSuQCAQGBEhdAUCgcCICKErEAgERkQIXYFAIDAiQugKBAKBEenY1gUwJ1QqVX5FRUX3ti5HW2JjY1Nw9+5dh7Yuh0BgrkjicETjkSRJbu/tJUkSsixLbV0OgcBcEeoFgUAgMCJC6AoEAoERETpdI3Hw4EEKCwtxcnLi0qVLXL16laFDh/KHP/yB6OhoioqKGDhwIB4eHvj7+5OUlFRvPlqtlo4dG/5n+/bbb0lISOD27duEh4djbW0NQGBgIA4ODhQWFrJ27VqD1FEgEDweMdM1EhMmTCAzM5O9e/cye/ZsAMaPHw/AuHHjuHr1Kp07d6ZXr14MGDBAL21RURFxcXGEh4eTnJxMWVkZarVaeY4fP67EjY+PJyQkhHHjxnHy5EklXKvVcuvWLezt7Y1QW4FA0BBC6BoJnU5HSUkJWq2W6upqvXcuLi5s2bKFzMzMetPOnz+fvLw8Zs6ciZeXV7O+//TTTxMSEkJ+fn6z0gsEgtZBqBeMxIYNG/D19aVjx45ERUUp4SUlJcTExHDv3j2eeeaZetPu2rULjUZDUlISXbp0YfLkyQQEBNQbd+rUqYSGhnL79m3CwsLYvHkz8+bNIycnB7VajZ2dnUHqJxAIGocwGWsCrWkytnv3bjp37szEiRP1wq9du0ZsbKzJ6l2FyZhA0DKE0G0CrSl04+PjmTp1ql5YYmIiL7/8MiqV6pFpb926xcqVK3niiSeYPXs2zz77LACnT5/m0KFD2NnZ8e677xITE8Pdu3dxc3Nj6NChqNVqbG1tmTVrVrN1u0LoCgQtQ6gXjMShQ4dITU3lypUrzJw5k9TUVEaOHElgYCAjRoygX79+nD17ltGjRytCd/v27ZSVlQHQvXt3pk+fDsDhw4d5/fXXcXV1JTIyktDQUADi4uIYPHgwUCOYDxw4wCuvvIIkSezatQtra2tkWeaJJ55ogxYQCAQgNtKMRmJiIkFBQYwaNUov3N3dncDAQD1Lg+ZSUFDAnDlzuH37Nj/++CNdu3Zl/vz57Ny5k6qqKkaOHMno0aPZs2dPi78lEAiah5jpGgkvLy/Wrl3L5cuXGThwoBJuZWVVu2Svk2bOnDn15uXp6UlISAifffYZs2bNIiUlBQcHB3x9fYmMjOTmzZsMGTIEZ2dn1Go1w4YNY/LkyajVagB8fX0NU0mBQPBYhE63CbREp5ufn8/+/fs5d+4cq1atwtbWtpVLZxyETlcgaBlC6DYB4fBGCF2BoKUI9YIJkpKSQmlpKd7e3s3OQ6vVsnr1akpLS1Gr1Rw8eJC0tDQuX77Mhx9+yCeffEJhYSH37t0jKCioFUsvEAgehRC6BiAmJgatVsugQYNwdnYmKSmJzMxMIiIimD17NmPGjOGbb75h+PDhZGRksGnTJsXnQmFhIcOGDQNgz549ZGVlodFoCA4OZsmSJQwZMgQvLy969uypxMnNzQVApVIxd+5cADp27EhISIhyiGLChAlMmDCBxYsXU1lZyZkzZ1i/fj2BgYGP9ecgEAhaD2G9YADc3NyorKxEo9FQXl5Ohw4d0Ol0XLx4EXt7e/z8/LC2tlZ+AZydnfHx8eH8+fNKPklJSTg6OmJnZ0dOTg5ubm4UFxfXOUbcWDZv3syECRPo3LmzEiZJQlMgEBgTMb0xAMXFxahUKjIyMpBlGZVKhU6no7q6WplRdurUCbgv9LKysoiOjqZ///5KPpMmTeLChQvY2trSo0cPbt++TWVlJdnZ2fTp0weAKVOmNFiOmJgY0tLSOHXqFOnp6Rw+fJhRo0YxcuRIXF1dWb9+PU899ZSY5QoERkRspDUBQ26kBQQEKCZdpozYSBMIWoYQuk1AWC8IoSsQtBSh0xUIBAIjIoSuAYiLiyM9Pb3F+fj7+3PixAkAsrOzGTlyJKWlpRw8eJDw8HDmzp1LVVVVnXR///vfCQsL48MPP+TatWvMmzePoKAgkpOT6/1OdHS0YuUQEhJCeHg4//rXvyguLsbb25vS0tIW10UgENQghG4zWbp0KVVVVajVanJzc9m6dSuhoaF6gq1WkNX+BgUFsXHjRmJjY5U4ubm5erdAnDlzRnlnbW3NqFGjuHPnDnv27OHVV18Fasy/li1bRufOnamsrKxTtnHjxpGfn0/Hjh3p2LEjZWVlFBUV0bt37zpxP/30U37zm98ANb59raysWLZsGf/+97/5xS9+oZivCQSC1kEI3Wbi7e1NQkIC169fx9HRkYqKCnr37s3Ro0frxK2urubmzZtkZmZia2tLUVFRk76VkpJCVVUVp06d4vDhw4C++dfdu3f14js5OaFWqyktLeXatWv4+vqybt069u7dS1VVFVqtVol78uRJjhw5QlpaGjqdTpiQCQQGRtgKNRMPDw9eeeUVFixYQHl5OTk5Obi4uKDT6ZQ4Dg4O7Nixg/Pnz9OtWzeee+45NBqN4n4RagRkQ7dA1PLaa6/x2muvUVlZiaenJ5s3b9Yz/woLC2P16tWKy8ZVq1bRoUMHunTpgp2dHXFxcRw9epTf/va3xMfH4+LiwgsvvABAZGQkAFeuXOGXv/wl1dXVrFu3Dg8Pj9ZuMoFAgLBeaBLGtl6IjY1lyJAhddxBPkx+fj4ODg6NyrMpcYuLi1m3bh0ffPCBcqBCWC8IBC1DCN0moFKp8isqKrq3dTnaEhsbm4K7d+82TmoLBII6CKFrYKQaJWk/oARIAjKBubIsax+ZsPW+/ytgPeAF/BcwQJblS8b4tkAgqIsQugZGkqRxwP8AnYBkYGlbnLCQJOkJ4HfA57IsN895g0AgaDHCesHwzAecgWzg7211pE2W5SpZlpOEwBUI2hZhvWBAflYteANlQAFw99EpmkZ70zELfbLAEhDqBQMjSdJAIMsQM9z25gtCWE4ILAEhdM0YIXQFAvPDbNUL7WFpLZbTAoHlYbYz3fYwy3vczK4pbXDw4EEKCwtxcnLi0qVLXL16laFDhzJq1Ci2bdtGQUEBU6ZMoVevXvj7+5OUlFRvPo252ic5OZmYmBgSExOVsO3bt6PRaDh06BAHDhzA09MTLy8vpkyZgpOTU6PqIGa6AkvAbGe6gqYxYcIEPvjgA77++ms2bNhASEgI48ePx87OjuXLl3Py5EkuXrzIqFGjGDBggF7aoqIi9u/fT0FBAYMHD2b06NFs375dee/m5qY4zcnIyKCsrIx+/frp5TFnzhy+/PJL5TScg4MDt27dwsrKysA1FwhMi3ZvMhYfH18nLDExsY4Tmfq4desWixcvZtmyZXp3mx04cIA1a9bw/vvvt2pZW4JOp6OkpAStVlvnjrWMjAySk5OZMWNGvWnnz59PXl4eM2fOxMvL65Hf+eKLL/jpp59IS0vT85gGsHfvXv74xz8CsHPnTt599109j2sCQXug3c10Dx06RGpqKleuXGHmzJmkpqYycuRIAgMDGTFiBP369ePs2bOMHj0alUoF1CyNy8rKAOjevTvTp08H4PDhw7z++uu4uroSGRlJaGioEr5+/Xo2btxIdnY2ffv2bZvKPsCGDRvw9fWlY8eOREVFKeHXr1/Hx8eHGTNmkJqayksvvVQn7a5du9BoNCQlJdGlSxcmT57coJOeRYsWATUOdFxdXdm8eTPz5s0jPz+fX/7yl1hbW5OXl8fHH39MXl4eb7zxhmEqLBCYKO1O6CYmJhIVFcXHH3+sF+7u7s7ixYtZvHgxXbt2baPSGY5aYQgwePBgdu/ezfHjx5k4cSLfffed8u7atWvKH5sH6dq1K2+++Wajv1d739u8efOAGnXCX/7yFwAcHR1ZtmxZs+ohEJg77U7oenl5sXbtWi5fvszAgQOVcCsrq9qNmjpp5syZU29enp6ehISE8NlnnzFr1ixSUlJwcHDA09OTsLAwNBqNScxy62PatGl1wuLj45k6dSpr165VwhITE3n55ZfrFcQPcuvWLVauXMkTTzzB7NmzefbZZ4Gamyi6dOlCnz59HnlzsUDQXmh31gv5+fns37+fc+fOsWrVKmxtbQ1QutahNa0X6uNhVUtCQgIBAQF1VC0BAQHY2dkBData9u3bh729fR1VS3R0NBUVFXTv3h0fH59ml/Xn+grrBYHZ0+420hwcHPD19UWtVpu0wDUGiYmJBAUF1fHX6+7uTmBgICdPnmzxN959913ee+89vv3223rvcxMI2hvtTr3QWFJSUigtLcXb27tF+ZSUlDBt2jTCw8OprKzk6NGjXLx4kfDwcH7xi1+0UmmbhzFULd9//z1ZWVlYW1srN1sIBO0Zi1UvxMTEoNVqGTRoEM7OziQlJZGZmUlERASzZ89mzJgxfPPNNwwfPpyMjAw2bdqEh4cH/v7+FBYWMmzYMEpLS9FqtWRlZaHRaAgODmbJkiUMGTIELy8vevbsCcCePXvIzc0FQKVSMXfuXADl6ptu3boxfPhw5ZLHsLAw3njjjTq2rPXU0aDqBXNStYBQLwgsA4tVL7i5uVFZWYlGo6G8vJwOHTqg0+m4ePEi9vb2+Pn5YW1trfwCODs74+Pjo2dzm5SUhKOjI3Z2duTk5ODm5kZxcXEdW9f6SEtLo7y8nCNHjigXSu7du5df/epXjxW4xkCoWgQC42Ox6oXi4mJUKhUZGRnIsoxKpUKn01FdXa0cY+3UqROAcgNuVlYW0dHR9O/fX8ln0qRJXLhwAVtbW3r06MHt27eprKwkOzubPn36ADS4Kz98+HCGDx9OXFwcw4YN47PPPiM2NhYvLy+uXr1a75XopkhrqFrKysrYvn07169fp0uXLvz+97/nk08+QafTMWfOHFxdXVuxxAKB6WKx6oXmEBAQoNiXmgKtpV4wBVVLLSEhIbz99tsUFxejVquRJImwsDCefvrpFreHQGAOWKx6oTmYksBtTUxB1QI1znIKCgro2bMnWVlZBAUFsXDhQg4ePGiQegsEpojFqhcE9zEFVQtAQkICkydPBqBbt27ExsZiZWXF22+/bYhqCwQmiUWrF2p1qbVWA83F39+fP//5z4waNYrs7GymTZvGF198wenTp0lLS+Py5ct8+OGHdUyiQkJCUKlU9OvXjz/96U9677799lsSEhK4ffs24eHhnDhxgsTERL3ZtqGtFx6FqalaQKgXBJaB2asXli5dSlVVFWq1mtzcXLZu3UpoaCjJyclKnFrnLLW/QUFBbNy4Uc/DVW5uLmq1Wnke9JBlbW3NqFGjuHPnDnv27OHVV18FatwlLlu2jM6dO1NZWalXrpKSEqysrFi2bBn//ve/65Q7Pj6ekJAQxo0bx8mTJxk/fnzrNUorYGoCVyCwFMxe6Hp7e5OQkMD169dxdHSkoqKC3r17c/To0Tpxq6uruXnzJpmZmdja2lJUVNSkb6WkpFBVVcWpU6cUE7DNmzczYcIEOnfuXMcdZO1SHUCWZSoqKppRQ4FAYEmYvdD18PBg27ZtjB07lvLycnJycpAkCZ1Op8RxcHBgx44dnD9/nm7duvHcc8+h0WgYPHiwEsfJyYmAgADlqc+E6bXXXiMoKAh3d3c8PT3ZvHkzhw8f5vz585SUlBASEqIcdX3qqaeUwxEeHh7k5ubqzaynTp1KaGgoKSkp9bpTbC3i4uJIT09vcT7+/v6cOHGiQR/CtRw9epSIiAiWLFkCwNy5c4mIiCA8PLzefJOTk5k0aRIAO3bsIDIykjVr1gAQHBxMQkJCi8suEJgUsiyb5VNTdOMQExMjHz9+/LHx8vLyGnxXWloq3717t8H3X375pbx161a9sJ/r+Ng2CAwMlCsrK+WoqCg5JydH3rJlixwSEiJ//vnn8kcffSSnpaXJCxculGVZVn6XL18ub9iwQY6JiVG+l5OTI0dFRSlPenq68q423aeffiofO3ZM1mg0cnBwcL11CQ0Nlf38/GRZluWZM2fKQUFB8s6dO+vEO3funBwfH6/kvWjRIlmWZXnJkiVyVVWVfPToUXnfvn2Nbg/xiMccHrOf6RoDPz+/Ok5h6qP2Kpr66Nq1KzY2Ng2+Hz9+fLN38Y2pYnmYqqoqtFqtXlhwcDB9+/blzp07PP/88/z1r38lPT0dWdZXsTR0y8SDahmBwNIwW5MxGxubAkmSLP424MbE8/Dw4JVXXmHBggWKisXFxaXZKpZH8bBjm/j4eFxcXHjhhReAGnXGjRs3yMnJwdramjNnzrB+/Xr69u1Lbm4ue/bsURyqP3zLhKurK+vXr+epp5567OWXAoG5YrYmYwLj3ogcGxvLkCFD6sz48/PzHznDfxCNRkOnTp0eOeN/kI0bNzJy5EhGjhwJCJMxgWUghK4Z0x6uoX8QIXQFloBYw5kx7UHF8iCNVbcIBKaMmOm2EyRJOgp8B0wHfi/LcsvtyJpeBgl4Eegsy/IRY39fIDAFhNBtB0iS1A84C2iASFmWI9q4SAJBu0WoF9oHqwEVcBkwiE5UpVLlV1RUWLSqw8bGpuDu3buN2zUUCBpAzHTbAZIk9QasZVnOMuA3LH5TT2zkCVoDIXQFrYIQugJB4xDqhRYgltQCgaCpiJluCxCzO714j22LgwcPUlhYiJOTE5cuXeLq1asMHTqUP/zhD0RHR1NUVMTAgQOVq4KSkpLqzUer1T7yxNo333zD6tWrCQkJ0fOlrFarKS8vJysri5UrV7J06VI8PDyYM2dOoy7mFDNdQWsgfC8IjMaECRPIzMxk7969zJ49G0DxIzxu3DiuXr1K586d6dWrFwMGDNBLW1RURFxcHOHh4SQnJ1NWVqbn//j48eNK3OHDh9d7iWZAQADdu3fnv//7v+nYsSP29vbcuXOHDh3EMBAYD9HbBEZDp9NRUlKCVqutc6+ai4sLW7ZsITMzs9608+fPJy8vj5kzZ+Ll5dXsMqSmpvLrX/8aJycnYmJiePXVV/nnP//Z7PwEgqYidLomQHx8PFOnTtULS0xM5OWXX0alUj0y7a1bt1i5ciVPPPEEs2fP5tlnnwXgwIEDpKenU1ZWRlhYmMHK3hQ2bNiAr68vHTt2JCoqSgkvKSkhJiaGe/fu8cwzz9SbdteuXWg0GpKSkujSpQuTJ09u0DnPxYsXOXjwIOfOnaNfv3588sknzJs3T7nxGCAzM5PExESuXr3K4sWLW7+yAkEDCJ1uC2iuTvfQoUOkpqZy5coVZs6cSUJCAgEBAQQGBjJixAj69evH2bNnCQgIwM7ODoDt27dTVlYGQPfu3Zk+fToA+/btw97eHldXVyIjIwkNDQVg8eLFrF+/no0bNzJx4kT69u3b3Dq2mk73YXbv3k3nzp2ZOHGiXvi1a9eIjY1l7dq1TSusgRE6XUFrINQLbUBiYiJBQUF1PHa5u7sTGBjIyZMn26hkxmXatGlMnDiR+Ph4vfBevXrx61//us71R/XR0E0Whw8fZuzYsZSWlgIQExNDZGQkKSkppKSkMG/ePHEPnKBNEOqFNsDLy4u1a9dy+fJlBg4cqIRbWVnVzqbqpJkzZ069eT3s3zYlJQUHBwc8PT0JCwtDo9E0e5ZrKB6e6aempjJy5Mg6M/3Ro0cr6pWGZvqHDx/m9ddfrzPT9/T05MSJE0CNYD5w4ACvvPIKkiTRqVMnunbtSmVlJdXV1VhZWbVBKwjaK0LotgGurq5cu3aNoqIihg4dqsx4a3WUTZmBPfnkk0RGRir/X6vTffbZZ/n973/fiqVuPRITE4mKiuLjjz/WC3d3d2fx4sUsXryYrl27ttr3qqur6dq1K/Pnz8fX15ctW7bg7u7Op59+yldffWVyNzELLBshdNsABwcHfH19HxsvJSWF0tLSes2fmsKDNrDTpk3jP//5DwsXLqz3anhjYIyZfnl5OadOnSI2Npbly5fj7OyMWq1m2LBhpKamcuzYMS5fvqxcgikQGAuxkdYCHrd5FBMTg1arZdCgQTg7O5OUlERmZiYRERHMnj2bMWPGKDvqGRkZbNq0STkYUFhYyLBhwygtLUWr1ZKVlYVGoyE4OJglS5YwZMgQvLy86NmzJwB79uwhNzcXAJVKxdy5c5VyZGRkEBkZibe3NyNGjCAhIYHz5883akZtiI20/Px89u/fz7lz51i1alWjDiaYAmIjTdAaiI00A+Lm5kZlZSUajYby8nI6dOiATqfj4sWL2Nvb4+fnh7W1tfIL4OzsjI+Pj96mUFJSEo6OjtjZ2ZGTk4ObmxvFxcV1bF0b4kEb2M8//5zy8nLS0tL0DhQYk9qZvlqtNhuBKxC0FkK9YECKi4tRqVRkZGQgyzIqlQqdTkd1dbVyjLVTp07A/Rtws7KyiI6Opn///ko+kyZN4sKFC9ja2tKjRw9u375NZWUl2dnZ9OnTB4ApU6bUW4aHbWDffPNNoMYs6ze/+Y2hqt7qtJaqpaSkhGnTphEeHs6wYcPaXNUiaH8I9UILMITvhYCAAJMyZWot9YIpqFqqq6tZt24d3bp1Y/jw4Tg4OBhE1SIQPAqhXjAxTEngtiamoGpJS0ujvLycI0eOcPjwYZNQtQjaH0K9IDAKpqBqGT58OMOHDycuLo5hw4YpHsjMTdUiMG+EeqEFNFa98PAgby7+/v78+c9/xtXVtV5/C7UcPXqUb7/9lvz8fCIiIrh37x5vv/02U6ZMqaMT/fbbb0lISOD27duEh4dz4sQJEhMTlRm3IY8BPw5zVbUIBI9CqBdaiaVLl1JVVYVarSY3N5etW7cSGhpKcnKyEqf28EPtb1BQEBs3biQ2NlaJk5ubq+ey8MyZM8o7a2trRo0apZzCWrFiBbt27apTlnHjxlFeXk55eTkAH374YR2HOrXEx8cTEhLCuHHjOHnypEkdFDAlgSsQtBZC6LYS3t7eJCQkcP36dRwdHamoqKB3794cPXq0Ttzq6mpu3rxJZmYmtra2FBUVtejbVVVVaLVavbDg4GD69u3L1atXycvL44svvuDw4cPIskxFRUWLvicQCJqPELqthIeHB9u2bWPs2LGUl5eTk5ODJEnodDoljoODAzt27OD8+fN069aN5557Do1Gw+DBg5U4Tk5OBAQEKI+rq2udb3l6epKQkMCaNWuYPn068fHxfP/998r7uLg41q1bx7Vr1+jduzcRERFMmTIFT09PcnNz9WbWU6dOJTQ0lJSUFF566aUm1VmqYbgkSX9pbJq4uDjS09Ob9J368Pf358SJEw06vHmQ6OjoBt1AZmdnM3LkSEpLS/n222/54IMPWLRoEZWVlRw5cqROOkmSfitJ0hMtroCg/SLLsnia+dQ0n/GIiYmRjx8/Xic8Ly+v0XmUlpbKd+/ebfD9l19+KW/dulX5/5/r+GCdrYEJQAyQC1wA1j3YFoGBgXJlZaUcFRUl5+TkyFu2bJFDQkLkzz//XP7oo4/ktLQ0eeHChbIsy8rv8uXL5Q0bNsgxMTFKPjk5OXJUVJTypKenK+9q03366afysWPHZI1GIwcHB9epz969e+UzZ84o8R/k9u3b8rp16+SVK1fKJSUlcmBgoKzVauX/+7//k48cOaL3ndq2AL4GioGdwJ+AJ2Uj9jnxmP8jrBfMCD8/v3rDHRwaf2/k4xzJ1KfTlSTJDngVmAz8DjgP/B/gKcvy+Z/jBNbGf5SqZdCgQXp5P6hqGThwoGJf21yqqqqQJEmxiDh58iTXrl0jLS2NoqIi/uu//kvxXJaSkkJVVRWnTp3i8OHDjcpfluWRkiT1ACYBc4BtkiSd/Lk9EmVZ/qlFFRBYPELotgAbG5sCSZIs/TbgyoqKimvAMWoES4Asy/mPSuPh4cErr7zCggULFFWLi4tLs1Utj+Jhhzfx8fG4uLjwwgsvACge2K5cucIvf/lLxbk7wGuvvcZrr71GZWUlnp6e9O3bl9DQUG7fvv3I2zZ+Fqybgc2SJD0JvELNH6Q1kiRdBBJ+bqsMWZaFeZBAD2EyJgBq9LPAUGqEx2SgD/AZNcLjC1mWbz8mvVHlS2xsLEOGDKnjCD4/P7/Bmb8sy9y4cYPu3Rv3d/LIkSNkZ2fz9ttvA483GftZ1zua+21YRU37/R9wUpblxjnLEFg0Qui2YyRJ6gj8hvtCAu7P0k7IsqxtKG09eVn8pK4pdro//xFzpaZdvQEnav6IJQCHZFm+Y7CCCkwaIXTbGZIkdaFGL+sN/B7I5v5s7IfmSk6VSpVfUVFh6aqWgrt37zZegf4AkiT1pkYPPBl4EUihps33y7J8o9UKKTB5hNBtB0iS5MD9Af8bIJX7Gz8t27kSNBlJkp6i5g/eZGosQc7y8x8+WZZ/bMuyCQyPELoWyM9L22e5rzZ4FkimZmB/Lsuypg2LJ3gASZI6AeO4/2+l4f7K42tZlnWPSC4wQ4TQtRAkSbIC3KlRG0wGVEAiNTrEr2RZrmzD4gkagSRJHYDh3BfAvwT2UyOAv5RlWRwltADMXuhaoi6xsbpDSZJUwMvUDFAvIJ/7s6TvLH5ny8KRJGkA9wWwK3CYmn/bz2RZLnognlV9lhGWODYepCU69rbE7IWuJe6aP7xLLknS84C1LMtfS5JkT42AnQyMB77jvj4wu00KLDA4kiR1A16j5t/9t8C31Py7p1BjFTFJluVvH0pjcWPjQczV65sQuibIg51JkqQxwKfALmrsaF2BQ9yf8RS3WUEFbYIkSf8FeFIjgCcCd4GnAR9Zlvc+EM/ixsaDCKHbRjyqYx08eJDCwkKcnJy4dOkSV69eZejQoUyaNInVq1dTWlqKWq0mIyODVatWsXv37nrz0Wq1yrHS+vjXv/7FxYsXKSwsVE5AAXp+bIcNG8bSpUvx8PBgzpw5j7yQsbYzSSK6zAYAACAASURBVJL0W2oEbCVwHNhIjY2n0O0JAJAk6RPgj0A5cFCW5akPvHuk0G1ofIwaNYpt27ZRUFDAlClT6NWrF/7+/iQlJdWbz+PGB0BycjIxMTEkJiYqYYGBgTg4OFBYWMjatWvx9PTEy8uLKVOm4OTk1Ji6m6XQtehjwBMmTOCDDz7g66+/ZsOGDYSEhDB+/Hg6duxISEiIcsTUxcWlzimmn376iaSkJEpLS/Hw8KBPnz7s2bNHeT9u3DjFA9if/vQnAP77v/9bL49aP7a1tyPY29tz584dOnRotHO3b4D/D+gMDADOCIEreIgFwNuyLN9tasKGxoednR3Lly/n5MmTXLx4kVGjRjFgwAC9tEVFRezfv5+CggIGDx7M6NGj2b59u/Lezc1NuY0jIyODsrIy+vXrp5eHVqvl1q1b2NvbAzVHw2/duoWVlVVTq2JWWLRrR51OR0lJCVqtttHXlQOUlZWxYMECqqqqeOedd+ocNX0YWZb561//qlyACJCTk6Pnx9bJyYmYmBheffVV/vnPfzaqHLIsa2RZXiPL8gpZlqfKsnyt0ZUQtAtkWS5qjsCFR4+PjIwMkpOTmTFjRr1p58+fT15eHjNnzsTLy+uR3/niiy/46aefSEtL03PK//TTTxMSEkJ+fo0rj507d/Luu+/quR61RCx6prthwwZ8fX3p2LEjUVFReu9iYmJIS0vj1KlTuLu7672ztbVl79693Lx5k3379tGvXz/GjRvXoPOV5cuXU1RUxPHjxxk2bBhbtmxh3rx5REREKFeHZ2ZmkpiYyNWrV1m8eLHB6iwQNJaGxsf169fx8fFhxowZpKam1utnedeuXWg0GpKSkujSpQuTJ09ucHwsWrQIqHE65OrqyubNm5k3bx45OTmo1Wrs7OzIy8vj448/Ji8vjzfeeMMwFTYRLFqn+zC7d++mc+fOTJw4US88IyODffv2sWLFCkMUscmYq65KYFo0dSOtofFx7do1YmNjWbt2bWsXsUWY6zhpV0LXXDDXziQwLSxxbDyIuY4Ti9bpNob4+Pg6YYmJidy9+3g1WUNXxYSEhBAREaG38SYQmAuGGBMHDhxgzZo1vP/++wDMmjULtVrNqVOn0Gq1ehvblo5F63Tr49ChQ6SmpnLlyhVmzpxJamoqI0eOJDAwkBEjRtCvXz/Onj3L6NGjlRsGtm/fTllZGQDdu3dn+vTpAMqtvK6urkRGRhIaGgpAt27dqKioEBdACswCY4yJw4cPs379ejZu3Eh2djYODg6KEH/YmsjSaXcz3cTERIKCgupYJLi7uxMYGMjJkydb/I13332X9957j2+//ZaqqqoW5ycQGBJjjImHCQsLY/ny5ezcubPV8zZ12t1M18vLi7Vr13L58mUGDhyohFtZWdXqiOqkmTNnTr15PXxVTEpKCg4ODnz//fdkZWVhbW3NE0+Ii2MFpo0xxoSnpydhYWFoNBr69u1LREQEZWVliq37o6yJLI12t5GWn5/P/v37OXfuHKtWrXrkybC2wlw3CASmRWPHhjmMifow13HS7oRuU6m1s/X29m5RPmFhYVhbWzNu3Dief/75R8Y1184kMC3MZWxER0dTVFTEwIED6d+/P5988gk6nY45c+YoM+H6MNdxYvHqhZiYGLRaLYMGDcLZ2ZmkpCQyMzOJiIhg9uzZjBkzhm+++Ybhw4eTkZHBpk2b8PDwwN/fn8LCQoYNGwbAnj17yMrKQqPREBwczJIlSxgyZAheXl707NlTiVN7hbhKpVJOqJ07d46MjAyef/55oW4QmAymMDag5kh9ZGQkzz//PNbW1pSWliJJEo6OjsZvFCNg8Rtpbm5uVFZWotFoKC8vp0OHDuh0Oi5evIi9vT1+fn5YW1srvwDOzs74+PjombwkJSXh6OiInZ0dOTk5uLm5UVxc3KjjxVVVVfTs2ZP/9//+Hx9++KHB6ioQNAVTGBtQ4/tky5YtZGZmkpWVRVBQEAsXLuTgwYMGqXdbY/Ez3eLiYlQqFRkZGciyjEqlQqfTKU5oADp16gTULFcAsrKyiI6Opn///ko+kyZN4sKFC9ja2tKjRw9u375NZWUl2dnZ9OnTB4ApU6bUW4ahQ4eyc+dO/ud//ofx48cbsLYCQeMxhbFRUlJCTEwM9+7d45lnnqFbt27ExsZiZWXF22+/bcDatx1Cp1sPAQEBqNXqVs2zKZirrkpgWlji2HgQcx0nQuiaIObamQSmhSWOjQcx13Fi8TpdgUAgMCXahdCNi4sjPT29xfn4+/tz4sSJBs+X13L06FEiIiJYsmRJnXd37txh48aNvP/++3z11VdkZGQwbdq0FpdNIGgOxh4be/bsYezYsfXmkZ+fj1qtZuHChVy4cIGDBw+iVqtxd3fnzp07bN++3WRUGy3BYoTu0qVLqaqqQq1Wk5uby9atWwkNDSU5OVmJU3u2u/Y3KCiIjRs36jlNzs3NRa1WK8+DTpetra0ZNWqUcr58xYoV7Nq1q05Zxo0bR3l5OeXl5XXede7cmRdffJFr166hUqnqvbVCIGhNTGls1F5dVR8ODg64uLhw/fp1rK2tmTBhAnPmzMHDw4POnTtbzCa0xQhdb29vEhISuH79Oo6OjlRUVNC7d2+OHj1aJ251dTU3b94kMzMTW1tbioqK6smx8VRVVaHVavXCgoOD6du3L9XV1XW8M7m7uxMbG8t3333Xou8KBI3B1MbGgzw8NiZMmEBwcDCZmZkA/P3vf2fmzJktKoOpYTEmYx4eHrzyyissWLCA8vJycnJycHFxQafTKXEcHBzYsWMH58+fp1u3bjz33HNoNBoGDx6sxHFycnqst6OHz5fHx8fj4uLCCy+8ANQs2W7cuEFOTg5WVlasWLGC9evXA3D58mX++c9/UlhYyKuvvmqAlhAI9DGlsZGSkkJaWhrbt29nxowZhISEEB4eDsB3333HoUOHyMnJYd68eQCkp6fz7rvvtnaTtCnCeqEJxMbGMmTIkDremPLz8xtUEciyzI0bN+jevXu97+u7tcJcd2UFpoWpj41a96d2dnaN+sbDN1uY6zgRQtcEMdfOJDAtLHFsPIi5jhOzVy/Y2NgUSJJU/zTSTLGxsSlo6zIIzB9LHBsPYq7jxOxnuo9CkqSdQCawEHhHluXENiiDCpgCdJFl2bLvlhaYLZIk/Q5wBbbIslzSBt8fCnwOfAj4AM9Z6jTdYoWuJEm/AK4B94DVsixHPSaJQCBoQyRJ8gY2AZ2AP8iyfKKNi2QQLMZkrB5WAJ2pUaEMauOyCASCx9MfsAK6AevauCwGw5JnusOBPkCCLMsNGwq2AiqVKr+iosKidGc2NjYFd+/eFac2WoDoF01HqnFn9hJgL8tygqG+05ZYrNA1Jpa4S2yuO8OmhOgXgvpotvWC+CsuEAgehyXKiYdpqtxo9kxX/BXXS9dgWxw8eJDCwkKcnJy4dOkSV69eZejQoYwaNYpt27ZRUFDAlClT6NWrF/7+/iQlJdWbj1arVRxL10dcXBw//vgjAwYM0LupNSqqZv/QxsYGPz8/PD098fLyYsqUKTg5OT2qTmJG00Ka0y+8vb1ZtmyZ4mugT58+BukXwcHB/OIXv8Da2hp/f3+D9QtLlBMP09Q2seSNNJNgwoQJZGZmsnfvXmbPng3A+PHjefrpp1m+fDl/+tOfuHTpEr169WLAgAF6aYuKioiLiyM8PJzk5GTKysr0HI4cP35ciWtra4tKpapzlj0nJ4dFixbx448/AjXHPW/duoWVlZWBay54FA31izNnzjB06FBCQkJISEgwWL8oKCggICCAxMQaK0rRL4yHELoGRqfTUVJSglarrXNnVEZGBsnJycyYMaPetPPnzycvL4+ZM2fi5eX1yO/84Q9/4IMPPuDevXtcvny5wXg7d+7k3Xff1fMeJTA+j+oXj6M1+sVvf/tboqOj6dy5MyD6hTFpsxNp8fHxTJ06VS8sMTGRl19+GZVK9ci0t27dYuXKlTzxxBPMnj2bZ599FoADBw6Qnp5OWVkZYWFhBit7U9iwYQO+vr507NhRWeoDXL9+HR8fH2bMmEFqaiovvfRSnbS7du1Co9GQlJREly5dmDx5coMOR5KTk0lLS+P69es4OTmxefNm5s2bR69evYiKimLgwIHk5eXx8ccfk5eXxxtvvGGwOgseT0P9wtXVlV27dhEaGtrg1eat0S9kWaa8vJy33nrLLPqFJckLo+l0Dx06RGpqKleuXGHmzJkkJCQQEBBAYGAgI0aMoF+/fpw9e5aAgADFAcb27dspKysDoHv37kyfPh2Affv2YW9vj6urK5GRkYSGhgKwePFi1q9fz8aNG5k4cSJ9+/Ztap1aXaf7MA877ajl2rVrxMbGsnbt2qZ+3iAInW7LEf2i+Tpdc5AXD9TRNHW6iYmJBAUF1fFC5O7uTmBgICdPnjRWUdqUadOm1RlYAL169TKZgSUwPqJf6GPJ8sJo6gUvLy/Wrl3L5cuXGThwoBJuZWVV+5eiTpoHd1sf5GGfnSkpKTg4OODp6UlYWBgajabZf7WMiSGWTAD/+Mc/OHz4MB999BGBgYE4ODhQWFjYLgevOWGM/iDLMsuWLaNHjx4EBARQUlLCtGnTCA8Pb/BGh7bAkuWF0dQL+fn57N+/n3PnzrFq1SpsbW2b9V1DYmj1gjGWTMeOHUOr1ZKYmIharWbRokV07dqVJ598kvfee8/gbSG4z+P6RVv0h7/97W8MHjyY//znPyxYsIB169bRrVs3hg8f3iihayz1gjnIi1qa2iZGm+k6ODjg6+vb6PgpKSmUlpY2uJnQGLRaLatXr6a0tNQkLrRLTEwkKiqKjz/+WC/c3d2dxYsXs3jxYrp27dqibxw9epSuXbuSlpZGdna2YpoWGBjYonwFrY+x+0NmZiY//PADubm5/PDDD7z00kuUl5dz5MgRSktLTWqm21h50RpyAiA6OpqioiIGDhyIg4MDu3fv5tlnn33sTRnNwWBCNyYmBq1Wy6BBg3B2diYpKYnMzEwiIiKYPXs2Y8aM4ZtvvmH48OFkZGSwadMmPDw88Pf3p7CwUOkAe/bsISsrC41GQ3BwMEuWLGHIkCF4eXnRs2dPJU5ubi4AKpWKuXPn1lSuY0dCQkIM0nDNwRhLppUrVwJw5coV+vbtS05ODmq1utHe+QXGw9j9YdCgQWzatIkrV66QkJDAiBEjGDFiBHFxcW0mcE1BTkDNZbKRkZE8//zz2NjY0LVrVyorK6murm5122WDCV03NzeOHz+ORqOhvLycDh06oNPpuHjxIvb29vj5+SlP7bLX2dkZHx8f5s2bpzRmUlISY8eORZIkcnJycHNzIz8/v8m2jaaAq6sr165do6ioSDmVBvdvYG3KbPzJJ58kMjJS+f8HdXgP5hUTE9PSYgsMRFv0B4A+ffroTURmzZrVnOK3CqYiJ1xcXNiyZQsRERFMnDgRd3d3Pv30U7766qtWv4XYYEK3uLgYlUpFRkYGsiyjUqnQ6XRUV1crxxY7deoE1OhEALKysoiOjqZ///5KPpMmTeLChQvY2trSo0cPbt++TWVlJdnZ2fTp0weouda5IWJiYkhLS+PUqVO4u7sbqLaNo6kqllpaawnV2KOeAuPQ3P5QiyGW1tOmTWtRXk3FFORESUkJMTEx3Lt3j2eeeYbU1FSOHTvG5cuXWbNmTavX2aR8LwQEBLSp7tVQG2mtsYQqLS1Fq9W2aAnl4+PDM888wzvvvIOjo6NB2kJwH3PpFxkZGURGRuLt7V2v2dpDdWpz3wttLScexmTtdBuDKTVka+Lm5kZlZeUjl1DW1tbKL9xfQp0/f17JJykpCUdHR+zs7JQlVHFxcaOXUOKop2lhKv2idmmdmZlpkHq2NuYuJ8z+YkpzwBSWUOZw1LO9YQr94uGltcDwGFy9ULsz2tLdUX9/f/785z/j6uraoBE4wI4dOygsLOTevXsEBQXpvSssLGT16tXKRsLp06f529/+xtatW2vrZPBjwI2lrZdQQr3QckS/aFwbmJKMuHPnDtu2beOnn37i1VdfJTs7W8815pEjRxSb5wfqaHz1wtKlS6mqqkKtVpObm8vWrVsJDQ0lOTlZiVO7W1r7GxQUxMaNG/WWurm5uXou6s6cOaO8s7a2ZtSoURw+fJjXX3+dFStWsGvXrjplOXPmDO+9957iwelB7O3t9XZtX3zxRbp06dIaTdDqmPsSSmAYzLVfmIuM6Ny5My+++CLXrl1DpVLVcY3ZGpYMrSJ0vb29SUhI4Pr16zg6OlJRUUHv3r05evRonbjV1dXcvHmTzMxMbG1tKSoqatG3q6qq6jQc3F+OPexHVCAQGB9zkhHu7u7Exsby3XffNdplalNoFaHr4eHBtm3bGDt2LOXl5eTk5CBJEjqdTonj4ODAjh07OH/+PN26deO5555Do9EwePBgJY6TkxMBAQHK4+rqWudbnp6eJCQksGbNGqZPn058fDzff/+98t7V1ZX169fz1FNP0bFjR1asWKG8q6ioYPv27Xz11VdkZGS0RtUbTVxcHOnp6S3Ox9/fnxMnTnDr1i0WL17MsmXL9DZVajl69CgREREsWbKkzrsLFy4QHh7OvHnzyMrKIiMjw+imQoIajN0v9uzZw9ixY+vN4/Tp04SHh+Pr60txcTGnT5/mnXfeaXHZwHxkxOXLlwkLC+Mvf/kLzs7OJCcnKwdYWs3MUpblZj01SY1HTEyMfPz48TrheXl5DabR6XRyfn5+g++//vprWa1WK///c52a3RaBgYFyZWWlHBUVJefk5MhbtmyRQ0JC5M8//1z+6KOP5LS0NHnhwoWyLMvK7/Lly+UNGzbIMTExSjlycnLkqKgo5UlPT1fe1ab79NNP5WPHjskajUYODg6ut36hoaGyn59fg/XfuXOnnJKSopdvS9tCPKbfLx7+t36YtWvXypcuXao3blP7hTHlhCFkxMN8+eWX8tatW/XCmtomJmUy9ij8/PzquHmDmr+ODSFJEt27N3wn3osvvsjChQtbpXxgekuo4OBg+vbtS3V1dZ0l1LFjxygoKGDMmDEt+q7g8Zhav3iQh/vF3r17+dWvfkW/fv1a9N22wBAy4mHGjx/P22+/3azy1dJsoWtjY1MgSRKW9NjY2BS0pDFNaQkVFxfHunXruHbtGlZWVnpLqLS0NJYuXUqHDh344YcfWlJlQSMwpX6RkpJCWloa27dvp6qqipCQEOXdZ599RmxsLEVFRVy9erVV6m6JcqKlcqPZJmOC+xjCNKghYmNjGTJkSJ2/6Pn5+Q3+RZdlmRs3bjT4Fz0jI4N9+/bpCWZhMtZyTL1fVFRUUFFR0aAzpNOnT5Oamqq3GhT9ouUIodsKGHNwGQsxuFqO6BeC+hAn0lqBn5dQjVcMmQEtVbUIRL8Q1I+Y6RoYSZKeATYDuUAfYKIsy6VGLkMHwA1YBMyXZbnYmN8X1EWSpJHA+4DVz8+fZFkub4NydAT+F3ABvge+kGX5U2OXoz0hhK6BkSQpEpgM/AT8WZbl3DYuksAEkCTpY2AUcB6YIctyy8wUWlYWG2ALMBbIlmV5dFuVpT0g1AsGRJIkCXiX++08gJoZr6AdI0mSCngT0AEVQG+gzYQu0I2ame7TgJMkSYNkWTYPl2NmiBC6hicS+DtwwdC7KiqVKr+iosLidIh3795t2NDSPKkE/gf4X1mWs9u6MLIs5wBukiT1APyAG21cJItGqBcsCLFbLhCYPmZzIk0gEAgsAbNXL4gltaA+RL+owRLbAcx7jJi9ekEsqfXSNdgWBw8epLCwECcnJy5dusTVq1cZOnQo3t7eLFu2jM6dOzN+/Hj69OmDv78/SUlJ9eaj1WqVWw3q49KlS/z973+nS5cuLFy4kCeeeAKAiIgIzp49S1xcHCkpKezevZtnn31Wz79xA3Vq9bYwV5rTFpbYDmDeaiehXmgnTJgwgczMTPbu3cvs2bOBGucdZ86cYejQoYSEhJCQkECvXr0YMGCAXtqioiLi4uIIDw8nOTmZsrIyPUfSx48fV+Ju2bIFe3t7JEl/PCxZskQ5bmpjY0PXrl2prKxs9D1eAoGl0O6Fbnx8fJ2wxMTERjk/b8h36YEDB1izZg3vv/9+q5a1Jeh0OsVTflMF3fz588nLy2PmzJl4eXk9Mm5FRQW/+93vcHJy4tixY/XGcXd3Jzw8nAEDBvDVV181qSzGor30i8Yg2qJ1MXudblM5dOgQqampXLlyhZkzZ5KamsrIkSMJDAxkxIgR9OvXj7NnzzJ69GhUKhUA27dvp6ysDIDu3bszffp0AOVaEFdXVyIjIwkNDVXC169fz8aNG8nOzqZv375tU9kH2LBhA76+vnTs2JGoqCgl3NXVlV27dhEaGoq3t3e9aXft2oVGoyEpKYkuXbowefLkBtUCs2bN4qOPPuLOnTt88MEHbN68mXnz5rFz507S0tI4ePAgTz75JMeOHePy5cusWbPGIPVtKu21X9SHaAvD0u6EbmJiIlFRUXz88cd64e7u7ixevJjFixfTtWvXNiqd4Vi0aJHy34MHD2b37t0cP36ciRMnsm7dOuVd7d1QD9O1a1fefPPNx37n4QsG582bB4CPjw8+Pj5K+K9//etm1cNQtNd+UR+iLQxLuxO6Xl5eyvUbAwcOVMKtrKxqlfN10syZM6fevDw9PQkJCeGzzz5j1qxZpKSk4ODggKenJ2FhYWg0GpP9Cz5t2rR6l43p6ekEBwc/Nv2tW7cavHH1H//4B4cPH+ajjz5ClmWWLVtGjx49CAgIoKSkhGnTphEeHt7i219bE9Ev7iPawrC0O+uF/Px89u/fz7lz51i1ahW2trYGLF3zMNSO/cPLxoSEBAICAuosGwMCApRNr4aWjfv27cPe3r7OsvHYsWNotVrlmuq//e1vDB48mP/85z8sWLCAdevW0a1bN4YPH94ooWss6wVL7RfNsV6w1LYwFdrdTNfBwQFfX9+2LkabYIxl49GjR+natStpaWlkZmbyww8/kJubyw8//MBLL71EeXk5R44cobS01KRmuu25XzyMaAvD0u6EblNJSUmhtLS0wU2mxnDjxg22bdtGQUEBU6ZMqfceJ2NgjGXjypUrAbhy5QqDBg1i06ZNXLlyhYSEBEaMGMGIESOIi4szKYHbHFqjX2i1WlavXk1paSlqtboVS2c8LGl8GAuLVy/ExMSg1WoZNGgQzs7OJCUlkZmZSUREBLNnz2bMmDF88803DB8+nIyMDDZt2oSHhwf+/v4UFhYybNgwSktL0Wq1ZGVlodFoCA4OZsmSJQwZMgQvLy969uwJ1FxvnZtb40RMpVIxd+5cvbKcPHmSixcv8tZbbz2uTgZZUpvDsvFhDNUWptQvAgICGiV0DaFeMKV2aOz4aG5bmAoWb6fr5uZGZWUlGo2G8vJyOnTogE6n4+LFi9jb2+Pn54e1tbXyC+Ds7IyPj4+eXWFSUhKOjo7Y2dmRk5ODm5sbxcXFjbZ5zcjIIDk5mRkzZhikno2hdtmoVqubJXBTUlJISEhocTmio6NZtWoVu3fvbnFezcVU+kVbYyrtYArjw1hYvHqhuLgYlUpFRkYGsiyjUqnQ6XRUV1crx1k7deoEoJyiysrKIjo6mv79+yv5TJo0iQsXLmBra0uPHj24ffs2lZWVZGdn06dPHwCmTJlSbxmuX7+Oj48PM2bMIDU1lZdeesmANW6Y1pjVQM2MpSWzmnHjxhEZGcnzzz9v/Eb4GVPoF1Dzb5KWlsapU6dwd3c3UG0bxhTawVTGh7GwePVCc2jscs9QGGpJ/fXXX3P8+HH69OmDi4sLKSkp/PDDD/j7+/O///u/fPjhh/j5+REbG8t7771HZGQkb731Fjt27GDevHlMmzaN0tJSEhISGDt2LPn5+bz++uucOHGC/Px83nzzTWWAPW4pqdPpiIiIYOnSpW3SFs3BHPuFJbYDmLd6weJnus2hrTuUoTCFWU1JSQkxMTHcu3ePZ555xoC1bX0stV80FdEOLUSWZbN+aqrwaD766CM5LS3tsfEeh5+fn3z8+HG5rKxMXrRokbx06VI5MzOzTrwtW7bIf/nLX+TVq1fXefdw2nPnzslTp07Vi/NznQzSFk1l4cKFrZ5nUzBkWxi7X/zrX/+Sx4wZU28eV69elQMDA+VFixbJN27ckL/++mv57bff1ovTnLZobJ8wdlvExcXJERER8l//+tc6786fPy+HhYXJc+fOlX/88cdWHSOm8FjMRtrSpUupqqpCrVaTm5vL1q1bCQ0NJTk5WYlT6y+g9jcoKIiNGzcSGxurxMnNzdXzoHXmzBnlnbW1NaNGjVLOk69YsYJdu3bVKcs777zD+++/z/Xr1+u8eziti4sLDg6m6xbU3Gc1ptQvpkyZ0qCp3N69e1mwYAGzZs0iKSmJF198kS5durRKG9RiSm1x5swZ3nvvPcUJ04M888wzLFu2jN/85jf89NNPJj9GmorFCF1vb28SEhK4fv06jo6OVFRU0Lt3b44ePVonbnV1NTdv3iQzMxNbW1uKilp2J2BVVZVex6msrGTFihUEBgYCNMobk8AwmFK/eBhj9wtTbItaNdbDbXHs2DEKCgoYM2ZMi75riliM0PXw8GDbtm2MHTuW8vJycnJykCQJnU6nxHFwcGDHjh2cP3+ebt268dxzz6HRaBg8eLASx8nJiYCAAOVxdXWt8y1PT08SEhJYs2YN06dPJz4+nu+//155P2vWLGRZ5vDhwwCsWLGiwbTGJi4ujvT09Bbn4+/vz4kTJxp03VfLnj17GDt2bL15nD59mvDwcHx9fSkuLub06dO88847LS7bg5hSv0hJSSEtLY3t27dTVVVFSEiI8u6Pf/wjH374ITt27His+0xLaAtXV1fWr1/PU089RceOHfXGSFpaGkuXLqVDhw788MMPBmmLNqWt9RstfTCAHrMhYmJi5OPHj9cJFW7W+AAACChJREFUz8vLazCNTqeT8/PzG3x/7ty5OrpfWqjHDAwMlCsrK+WoqCg5JydH3rJlixwSEiJ//vnniu6uVldb+7t8+XJ5w4YNckxMjFKOnJwcOSoqSnnS09OVd7XpPv30U/nYsWOyRqORg4OD663j4/TCa9eulS9dulRv3Ja2hTFoTr+4e/euXFJS0uD7r7/+Wlar1XphzWkLY7aDLJv+GDGFR1gvNAE/P796wx+lb5Ikie7dG76iysXFBRcXlxaX7UEetYwcNGiQXtwHl5EDBw5UzLyaS1VVFZIkNXilz927d/VcR+7du5df/epX9OvXr0XfbUua0y9sbGywsbFp8P2LL77Iiy++2OKyGRtzGSNtidmrF2xsbAokScKSHhsbm4KWtIkpLSMftaT+7LPPiI2NpaioiKtXr7akynUQ/cJy26E1xkhbYvaHIwT3kYx4CWFsbCxDhgyp45wkPz+/wVlNRUUFFRUVitvIhzl9+jSpqaksXLhQCZMk8zWCFwjqQwhdC8KYQtdYCKErsDSETteC+Hkp2bByzAwx52WkQFAfZq/TFdzn7t27DrIsS/U9QCzgC+QD7zQUz9APMBIoAN4GTgFWj4p/9+5dy7GKFwgQ6oV2gSRJTwHXgHtAsCzLMW1cnrHAP4BqYI4sy4fbsjwCgTERM932QRDQBbABftvGZQFwB2yBXwFr27gsAoFRETPddoAkSW8A/YG/ybLcsvOcrYQkSSrAGxggy/Jf2ro8AoGxEEJXIBAIjIhQLwgEAoERESZjrYBKpcqvqKiwOFOt5lgOiLYQCB6NUC+0AuJQgl460RYCwSMQ6gWBQCAwIkLomgDx8fF1whITExvl5Lohf7YHDhxgzZo1vP/++61aVkMj2kJg6Qidbhtw6NAhUlNTuXLlCjNnziQ1NZWRI0cSGBjIiBEj6NevH2fPnmX06NGKG8Tt27dTVlYGQPfu3RUH6LXXori6uhIZGUloaKgSvn79ejZu3Eh2djZ9+/Ztm8o+BtEWgvaGmOm2AYmJiQQFBdXx0OXu7k5gYCAnT55so5IZH9EWgvaGmOm2AV5eXqxdu5bLly8zcOBAJdzKyqp206ZOmjlz5tSbl6enJyEhIXz22WfMmjWLlJQUHBwc8PT0JCwsDI1GY9IzO9EWgvaGsF5oBZq6Y5+fn8/+/fs5d+4cq1atwtbW1oClax7Gsl6w5LYQCOpDCN1WQJhJ6aUTbSEQPAKh0zUDUlJSSEhIaFEeWq2WkJAQAgICWqlUbUNrtMWNGzdYu3YtAQEBnDhxopVKJhA0DjHTbQUeN7uLiYlBq9UyaNAgnJ2dSUpKIjMzk4iICGbPns2YMWP45ptvGD58OBkZGWzatAkPDw/8/f0pLCxk2LBhlJaWotVqycrKQqPREBwczJIlSxgyZAheXl707NkTqLnyvPZySZVKxdy5c/XKEhAQgFqtbkydDDLTNaW2OHnyJBcvXuStt94ySFsIBPUhZrpGwM3NjcrKSjQaDeXl5XTo0AGdTsfFixext7fHz88Pa2tr5RfA2dkZHx8fPXvTpKQkHB0dsbOzIycnBzc3N4qLi6murm6rqjUZU2mLjIwMkpOTmTFjhkHqKRA0hLBeMALFxcWoVCoyMjKQZRmVSoVOp6O6ulq5qrxTp05AzawKICsri+joaPr376/kM2nSJC5cuICtrS09evTg9u3bVFZWkp2dTZ8+fQCYMmVKg+WIiYkhLS2NU6dO4e7ubqDaPhpTaIvr16/j4+PDjBkzSE1N5aWXXjJgjQUCfYR6oRUwxOZRY9UAhsKUNtLMtS0EgvoQQrcVEDv2eulEWwgEj0DodI1IXFwc6enpLc7H39+fEydONOhroJY9e/YwduzY/7+9OwZJJozDAP4YEQ0RNkQKgqOgxTU1RFFDY4OQg20ODi2RFJyQSy5CQyESuFRwUzhIDg5uRUvgIhpY0VYa6RHREgeX2tTxlfYhed9LXzw/OBz+73kv/+FBefV9O77H7e0tZFnG+vo6VFVFPp9HMBjseW7dEN0HRVGws7ODWCzWVru+vsb29jZWVlZwc3ODcrkMv9/f89yIvsLQNZksy9B1HfF4HJVKBfv7+4hGo8jlcsaY959tvb9ubm4ikUggmUwaYyqVCuLxuHEVi0WjNjAwgJmZGWOvgUgkgqOjo7a5+Hw+TE5OdpxnOp3G6uoqAoEAstkspqamMDQ0ZEoPgJ/Vh2KxiI2NDTw9PeH19fVDzeVyIRwOY3Z2Fvf393C73bDZuHUu/TsMXZN5vV5kMhlUq1XY7XZomgan04mTk5O2sY1GA6qq4vLyEsPDw3h87O34Ml3X20LlT93s1GWWn9iH94W5z304OztDrVbD3NxcT88l6gZD12TT09M4ODjA/Pw8Xl5ecHd3B4vFgmazaYyx2WxQFAVXV1cYHR3F+Pg4np+f4fF4jDEOhwOhUMi4JElqe9bCwgIymQxisRiWl5eRSqVQKpWM+unpKQqFAg4PD6HrOra2toza0tIS9vb2oCgKFhcXf3UfJEnC7u4uRkZG0N/fj0gkYtQKhQJkWUZfXx8uLi5M7wPRZ1xIM4HoxaNkMomJiYm2nbkeHh6+/GqsaRo0TYPVau1Yz+fzOD8/x9raGoD/YyHtO31otVqo1+sYG+t8olC5XMbx8fGHYOZCGpmJoWsCrth/uI+9IPoL/jnCBIODgzWLxfLrDmP87n3sBdHX+EmXiEggLqQREQnE0CUiEoihS0QkEEOXiEgghi4RkUAMXSIigRi6REQCMXSJiARi6BIRCcTQJSIS6A0bgWc7ggN4IgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The cell below just shows the confusion matrices from the decision tree created from scratch that uses information gain, followed by the sk learn tree, which uses gini."
      ],
      "metadata": {
        "id": "YBLH1l-1Mi2N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"From scratch w/entroy:\\n{cm_scratch}\\n\")\n",
        "print(f\"Sk learn with gini:\\n{cm_sklearn}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImuL1e9HwhKt",
        "outputId": "c28f16c1-d0fb-4c40-f234-36c50ed3c9e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From scratch w/entroy:\n",
            "[[ 8  0  0]\n",
            " [ 0 12  2]\n",
            " [ 0  0  8]]\n",
            "\n",
            "Sk learn with gini:\n",
            "[[ 8  0  0]\n",
            " [ 0 12  0]\n",
            " [ 0  2  8]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEBH56pukq_H"
      },
      "source": [
        "### Q2 Linear Regression (40 points)\n",
        "\n",
        "Linear regression attempts to model the relationship between two variables by fitting a linear equation to observed data. One variable is considered to be an explanatory variable, and the other is considered to be a dependent variable. \n",
        "<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FL1tuQEkq_H"
      },
      "source": [
        "## Gradient descent algorithm \n",
        "\\begin{equation}\n",
        "\\theta^{+} = \\theta^{-} + \\frac{\\alpha}{m} (y_{i} - h(x_{i}) )\\bar{x}\n",
        "\\end{equation}\n",
        "\n",
        "This minimizes the following cost function\n",
        "\n",
        "\\begin{equation}\n",
        "J(x, \\theta, y) = \\frac{1}{2m}\\sum_{i=1}^{m}(h(x_i) - y_i)^2\n",
        "\\end{equation}\n",
        "\n",
        "where\n",
        "\\begin{equation}\n",
        "h(x_i) = \\theta^T \\bar{x}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOem1EjQkq_H"
      },
      "outputs": [],
      "source": [
        "# Do not change the code in this cell\n",
        "true_slope = 15\n",
        "true_intercept = 2.4\n",
        "input_var = np.arange(0.0,100.0)\n",
        "output_var = true_slope * input_var + true_intercept + 300.0 * np.random.rand(len(input_var))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "SNvDqYEykq_H",
        "outputId": "ee9e9162-0d80-41ac-b93b-4617b847c432",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Do not change the code in this cell\n",
        "plt.figure()\n",
        "plt.scatter(input_var, output_var)\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgNhbpEmkq_I"
      },
      "outputs": [],
      "source": [
        "def compute_cost(ip, op, params):\n",
        "    \"\"\"\n",
        "    Cost function in linear regression where the cost is calculated\n",
        "    ip: input variables\n",
        "    op: output variables\n",
        "    params: corresponding parameters\n",
        "    Returns cost\n",
        "    \"\"\"\n",
        "    num_samples = len(ip)\n",
        "    cost_sum = 0.0\n",
        "    for x,y in zip(ip, op):\n",
        "        y_hat = np.dot(params, np.array([1.0, x]))\n",
        "        cost_sum += (y_hat - y) ** 2\n",
        "    \n",
        "    cost = cost_sum / (num_samples)\n",
        "    \n",
        "    return cost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMIwPHznVG6w"
      },
      "source": [
        "### Q2.1 Implement Linear Regression using Batch Gradient Descent from scratch.  (15 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ao7aYu9kq_I"
      },
      "source": [
        "\n",
        "### Batch gradient descent\n",
        "Algorithm can be given as follows:\n",
        "\n",
        "```for j in 0 -> max_iteration: \n",
        "    for i in 0 -> m: \n",
        "        theta += (alpha / m) * (y[i] - h(x[i])) * x_bar\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " I really tried my hardest to complete this question using vector/matrix operations rather than operating on each component, but I found my learning rate needed to be adjusted in that scenario, which isn't permitted.  I still don't understand why that should be the case. \n",
        "\n",
        "  In order to complete the exercise without changing the learning rate, I switched to operating on an example at a time. I left the code in the cell, but commented out to show my thought process.\n"
      ],
      "metadata": {
        "id": "c26P1VUqwAul"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0z876gDkq_I"
      },
      "outputs": [],
      "source": [
        "def linear_regression_using_batch_gradient_descent(ip, op, params, alpha, max_iter):\n",
        "    \"\"\"\n",
        "    Compute the params for linear regression using batch gradient descent\n",
        "    ip: input variables\n",
        "    op: output variables\n",
        "    params: corresponding parameters\n",
        "    alpha: learning rate\n",
        "    max_iter: maximum number of iterations\n",
        "    Returns parameters, cost, params_store\n",
        "    \"\"\" \n",
        "    # initialize iteration, number of samples, cost and parameter array\n",
        "    iteration = 0\n",
        "    num_samples = len(ip)\n",
        "    cost = np.zeros(max_iter)\n",
        "    params_store = np.zeros([2, max_iter])\n",
        "    \n",
        "    # These variables were meant to support calculating\n",
        "    # the gradient at the matrix level.\n",
        "    #intercepts = np.ones_like(ip)\n",
        "    #X = np.array([np.ones(len(ip)), ip.flatten()]).T \n",
        "\n",
        "    # Compute the cost and store the params for the corresponding cost\n",
        "    while iteration < max_iter:\n",
        "        cost[iteration] = compute_cost(ip, op, params)\n",
        "        params_store[:, iteration] = params\n",
        "        \n",
        "        print('--------------------------')\n",
        "        print(f'iteration: {iteration}')\n",
        "        print(f'cost: {cost[iteration]}')\n",
        "        print(f'params: {params}')\n",
        " \n",
        " \n",
        "        # Apply batch gradient descent\n",
        "\n",
        "        # ended up looping over each example\n",
        "        for x, y in zip(ip, op):\n",
        "          y_hat = np.dot(params, np.array([1.0, x]))\n",
        "          gradient = np.array([1.0, x]) * (y - y_hat)\n",
        "          params += alpha * gradient/num_samples\n",
        "           \n",
        "        # The below code was my attempt to use\n",
        "        # matrix computations to avoid explicitly\n",
        "        # looping.  It worked, but not without modifying\n",
        "        # alpha, which was prohibited. Not sure why it \n",
        "        # would appear to work, but only with a reduced learning rate.\n",
        "\n",
        "        #preds = X.dot(params)\n",
        "        #loss = op - preds\n",
        "        #grad = loss.dot(X)\n",
        "        #new_params = (alpha/len(X)) * grad\n",
        "        #params += new_params\n",
        "\n",
        "        iteration += 1    \n",
        "    return params, cost, params_store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbjhyZ71kq_I",
        "outputId": "2e9f6cb2-8801-4a23-cd02-0f08a2f64f8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------\n",
            "iteration: 0\n",
            "cost: 11910175.085004052\n",
            "params: [20. 80.]\n",
            "--------------------------\n",
            "iteration: 1\n",
            "cost: 34693.87267492755\n",
            "params: [19.11365509 19.77550869]\n",
            "--------------------------\n",
            "iteration: 2\n",
            "cost: 9918.993731939318\n",
            "params: [19.10016328 17.06205194]\n",
            "--------------------------\n",
            "iteration: 3\n",
            "cost: 9836.864925339762\n",
            "params: [19.12598503 16.93938474]\n",
            "--------------------------\n",
            "iteration: 4\n",
            "cost: 9833.813196061466\n",
            "params: [19.1535706 16.933429 ]\n",
            "--------------------------\n",
            "iteration: 5\n",
            "cost: 9832.227091165758\n",
            "params: [19.18122844 16.93273106]\n",
            "--------------------------\n",
            "iteration: 6\n",
            "cost: 9830.703523962617\n",
            "params: [19.20888233 16.9322701 ]\n",
            "--------------------------\n",
            "iteration: 7\n",
            "cost: 9829.183557850012\n",
            "params: [19.23652884 16.93181992]\n",
            "--------------------------\n",
            "iteration: 8\n",
            "cost: 9827.664547088209\n",
            "params: [19.26416783 16.93137035]\n",
            "--------------------------\n",
            "iteration: 9\n",
            "cost: 9826.146372123892\n",
            "params: [19.29179929 16.93092093]\n",
            "--------------------------\n",
            "iteration: 10\n",
            "cost: 9824.629027140994\n",
            "params: [19.31942322 16.93047162]\n",
            "--------------------------\n",
            "iteration: 11\n",
            "cost: 9823.11251144524\n",
            "params: [19.34703963 16.93002244]\n",
            "--------------------------\n",
            "iteration: 12\n",
            "cost: 9821.596824573191\n",
            "params: [19.37464851 16.92957338]\n",
            "--------------------------\n",
            "iteration: 13\n",
            "cost: 9820.081966072088\n",
            "params: [19.40224986 16.92912445]\n",
            "--------------------------\n",
            "iteration: 14\n",
            "cost: 9818.567935489853\n",
            "params: [19.4298437  16.92867563]\n",
            "--------------------------\n",
            "iteration: 15\n",
            "cost: 9817.054732374683\n",
            "params: [19.45743002 16.92822694]\n",
            "--------------------------\n",
            "iteration: 16\n",
            "cost: 9815.542356275033\n",
            "params: [19.48500882 16.92777837]\n",
            "--------------------------\n",
            "iteration: 17\n",
            "cost: 9814.030806739593\n",
            "params: [19.5125801  16.92732993]\n",
            "--------------------------\n",
            "iteration: 18\n",
            "cost: 9812.520083317313\n",
            "params: [19.54014388 16.9268816 ]\n",
            "--------------------------\n",
            "iteration: 19\n",
            "cost: 9811.010185557363\n",
            "params: [19.56770014 16.9264334 ]\n",
            "--------------------------\n",
            "iteration: 20\n",
            "cost: 9809.50111300919\n",
            "params: [19.59524889 16.92598532]\n",
            "--------------------------\n",
            "iteration: 21\n",
            "cost: 9807.992865222463\n",
            "params: [19.62279014 16.92553736]\n",
            "--------------------------\n",
            "iteration: 22\n",
            "cost: 9806.485441747102\n",
            "params: [19.65032388 16.92508953]\n",
            "--------------------------\n",
            "iteration: 23\n",
            "cost: 9804.97884213328\n",
            "params: [19.67785012 16.92464181]\n",
            "--------------------------\n",
            "iteration: 24\n",
            "cost: 9803.473065931406\n",
            "params: [19.70536886 16.92419422]\n",
            "--------------------------\n",
            "iteration: 25\n",
            "cost: 9801.968112692151\n",
            "params: [19.73288011 16.92374675]\n",
            "--------------------------\n",
            "iteration: 26\n",
            "cost: 9800.463981966408\n",
            "params: [19.76038385 16.9232994 ]\n",
            "--------------------------\n",
            "iteration: 27\n",
            "cost: 9798.96067330533\n",
            "params: [19.78788011 16.92285218]\n",
            "--------------------------\n",
            "iteration: 28\n",
            "cost: 9797.458186260306\n",
            "params: [19.81536887 16.92240507]\n",
            "--------------------------\n",
            "iteration: 29\n",
            "cost: 9795.956520382973\n",
            "params: [19.84285014 16.92195809]\n",
            "--------------------------\n",
            "iteration: 30\n",
            "cost: 9794.455675225225\n",
            "params: [19.87032392 16.92151123]\n",
            "--------------------------\n",
            "iteration: 31\n",
            "cost: 9792.955650339178\n",
            "params: [19.89779021 16.92106449]\n",
            "--------------------------\n",
            "iteration: 32\n",
            "cost: 9791.45644527721\n",
            "params: [19.92524903 16.92061787]\n",
            "--------------------------\n",
            "iteration: 33\n",
            "cost: 9789.95805959193\n",
            "params: [19.95270036 16.92017138]\n",
            "--------------------------\n",
            "iteration: 34\n",
            "cost: 9788.460492836204\n",
            "params: [19.98014421 16.919725  ]\n",
            "--------------------------\n",
            "iteration: 35\n",
            "cost: 9786.963744563132\n",
            "params: [20.00758058 16.91927875]\n",
            "--------------------------\n",
            "iteration: 36\n",
            "cost: 9785.467814326053\n",
            "params: [20.03500948 16.91883262]\n",
            "--------------------------\n",
            "iteration: 37\n",
            "cost: 9783.97270167858\n",
            "params: [20.0624309  16.91838661]\n",
            "--------------------------\n",
            "iteration: 38\n",
            "cost: 9782.47840617452\n",
            "params: [20.08984485 16.91794072]\n",
            "--------------------------\n",
            "iteration: 39\n",
            "cost: 9780.98492736796\n",
            "params: [20.11725133 16.91749496]\n",
            "--------------------------\n",
            "iteration: 40\n",
            "cost: 9779.492264813227\n",
            "params: [20.14465034 16.91704931]\n",
            "--------------------------\n",
            "iteration: 41\n",
            "cost: 9778.000418064881\n",
            "params: [20.17204189 16.91660379]\n",
            "--------------------------\n",
            "iteration: 42\n",
            "cost: 9776.50938667772\n",
            "params: [20.19942598 16.91615839]\n",
            "--------------------------\n",
            "iteration: 43\n",
            "cost: 9775.019170206799\n",
            "params: [20.2268026  16.91571311]\n",
            "--------------------------\n",
            "iteration: 44\n",
            "cost: 9773.529768207414\n",
            "params: [20.25417176 16.91526795]\n",
            "--------------------------\n",
            "iteration: 45\n",
            "cost: 9772.041180235088\n",
            "params: [20.28153347 16.91482291]\n",
            "--------------------------\n",
            "iteration: 46\n",
            "cost: 9770.55340584561\n",
            "params: [20.30888772 16.91437799]\n",
            "--------------------------\n",
            "iteration: 47\n",
            "cost: 9769.066444594991\n",
            "params: [20.33623452 16.9139332 ]\n",
            "--------------------------\n",
            "iteration: 48\n",
            "cost: 9767.580296039496\n",
            "params: [20.36357386 16.91348852]\n",
            "--------------------------\n",
            "iteration: 49\n",
            "cost: 9766.09495973562\n",
            "params: [20.39090576 16.91304397]\n",
            "--------------------------\n",
            "iteration: 50\n",
            "cost: 9764.61043524012\n",
            "params: [20.41823021 16.91259954]\n",
            "--------------------------\n",
            "iteration: 51\n",
            "cost: 9763.126722109966\n",
            "params: [20.44554721 16.91215523]\n",
            "--------------------------\n",
            "iteration: 52\n",
            "cost: 9761.6438199024\n",
            "params: [20.47285677 16.91171104]\n",
            "--------------------------\n",
            "iteration: 53\n",
            "cost: 9760.161728174879\n",
            "params: [20.50015889 16.91126697]\n",
            "--------------------------\n",
            "iteration: 54\n",
            "cost: 9758.68044648513\n",
            "params: [20.52745357 16.91082302]\n",
            "--------------------------\n",
            "iteration: 55\n",
            "cost: 9757.199974391087\n",
            "params: [20.55474082 16.91037919]\n",
            "--------------------------\n",
            "iteration: 56\n",
            "cost: 9755.720311450948\n",
            "params: [20.58202062 16.90993549]\n",
            "--------------------------\n",
            "iteration: 57\n",
            "cost: 9754.241457223166\n",
            "params: [20.609293  16.9094919]\n",
            "--------------------------\n",
            "iteration: 58\n",
            "cost: 9752.76341126639\n",
            "params: [20.63655794 16.90904844]\n",
            "--------------------------\n",
            "iteration: 59\n",
            "cost: 9751.286173139535\n",
            "params: [20.66381546 16.90860509]\n",
            "--------------------------\n",
            "iteration: 60\n",
            "cost: 9749.809742401776\n",
            "params: [20.69106554 16.90816187]\n",
            "--------------------------\n",
            "iteration: 61\n",
            "cost: 9748.3341186125\n",
            "params: [20.71830821 16.90771877]\n",
            "--------------------------\n",
            "iteration: 62\n",
            "cost: 9746.859301331333\n",
            "params: [20.74554344 16.90727579]\n",
            "--------------------------\n",
            "iteration: 63\n",
            "cost: 9745.385290118165\n",
            "params: [20.77277126 16.90683293]\n",
            "--------------------------\n",
            "iteration: 64\n",
            "cost: 9743.912084533114\n",
            "params: [20.79999166 16.90639019]\n",
            "--------------------------\n",
            "iteration: 65\n",
            "cost: 9742.43968413652\n",
            "params: [20.82720464 16.90594757]\n",
            "--------------------------\n",
            "iteration: 66\n",
            "cost: 9740.968088488991\n",
            "params: [20.85441021 16.90550507]\n",
            "--------------------------\n",
            "iteration: 67\n",
            "cost: 9739.497297151367\n",
            "params: [20.88160837 16.90506269]\n",
            "--------------------------\n",
            "iteration: 68\n",
            "cost: 9738.02730968472\n",
            "params: [20.90879911 16.90462044]\n",
            "--------------------------\n",
            "iteration: 69\n",
            "cost: 9736.558125650354\n",
            "params: [20.93598245 16.9041783 ]\n",
            "--------------------------\n",
            "iteration: 70\n",
            "cost: 9735.089744609828\n",
            "params: [20.96315837 16.90373628]\n",
            "--------------------------\n",
            "iteration: 71\n",
            "cost: 9733.622166124947\n",
            "params: [20.9903269  16.90329439]\n",
            "--------------------------\n",
            "iteration: 72\n",
            "cost: 9732.155389757725\n",
            "params: [21.01748802 16.90285261]\n",
            "--------------------------\n",
            "iteration: 73\n",
            "cost: 9730.689415070445\n",
            "params: [21.04464174 16.90241096]\n",
            "--------------------------\n",
            "iteration: 74\n",
            "cost: 9729.224241625609\n",
            "params: [21.07178806 16.90196942]\n",
            "--------------------------\n",
            "iteration: 75\n",
            "cost: 9727.75986898596\n",
            "params: [21.09892698 16.90152801]\n",
            "--------------------------\n",
            "iteration: 76\n",
            "cost: 9726.296296714503\n",
            "params: [21.12605851 16.90108672]\n",
            "--------------------------\n",
            "iteration: 77\n",
            "cost: 9724.83352437445\n",
            "params: [21.15318265 16.90064554]\n",
            "--------------------------\n",
            "iteration: 78\n",
            "cost: 9723.37155152926\n",
            "params: [21.18029939 16.90020449]\n",
            "--------------------------\n",
            "iteration: 79\n",
            "cost: 9721.910377742639\n",
            "params: [21.20740875 16.89976355]\n",
            "--------------------------\n",
            "iteration: 80\n",
            "cost: 9720.450002578527\n",
            "params: [21.23451072 16.89932274]\n",
            "--------------------------\n",
            "iteration: 81\n",
            "cost: 9718.990425601096\n",
            "params: [21.26160531 16.89888205]\n",
            "--------------------------\n",
            "iteration: 82\n",
            "cost: 9717.531646374764\n",
            "params: [21.28869251 16.89844147]\n",
            "--------------------------\n",
            "iteration: 83\n",
            "cost: 9716.07366446418\n",
            "params: [21.31577233 16.89800102]\n",
            "--------------------------\n",
            "iteration: 84\n",
            "cost: 9714.616479434237\n",
            "params: [21.34284477 16.89756069]\n",
            "--------------------------\n",
            "iteration: 85\n",
            "cost: 9713.160090850059\n",
            "params: [21.36990984 16.89712048]\n",
            "--------------------------\n",
            "iteration: 86\n",
            "cost: 9711.704498277011\n",
            "params: [21.39696753 16.89668038]\n",
            "--------------------------\n",
            "iteration: 87\n",
            "cost: 9710.249701280682\n",
            "params: [21.42401785 16.89624041]\n",
            "--------------------------\n",
            "iteration: 88\n",
            "cost: 9708.79569942693\n",
            "params: [21.4510608  16.89580056]\n",
            "--------------------------\n",
            "iteration: 89\n",
            "cost: 9707.342492281807\n",
            "params: [21.47809638 16.89536082]\n",
            "--------------------------\n",
            "iteration: 90\n",
            "cost: 9705.890079411645\n",
            "params: [21.5051246  16.89492121]\n",
            "--------------------------\n",
            "iteration: 91\n",
            "cost: 9704.438460382973\n",
            "params: [21.53214545 16.89448171]\n",
            "--------------------------\n",
            "iteration: 92\n",
            "cost: 9702.987634762581\n",
            "params: [21.55915893 16.89404234]\n",
            "--------------------------\n",
            "iteration: 93\n",
            "cost: 9701.537602117494\n",
            "params: [21.58616506 16.89360309]\n",
            "--------------------------\n",
            "iteration: 94\n",
            "cost: 9700.088362014967\n",
            "params: [21.61316383 16.89316395]\n",
            "--------------------------\n",
            "iteration: 95\n",
            "cost: 9698.639914022484\n",
            "params: [21.64015524 16.89272494]\n",
            "--------------------------\n",
            "iteration: 96\n",
            "cost: 9697.19225770778\n",
            "params: [21.6671393  16.89228604]\n",
            "--------------------------\n",
            "iteration: 97\n",
            "cost: 9695.745392638812\n",
            "params: [21.694116   16.89184727]\n",
            "--------------------------\n",
            "iteration: 98\n",
            "cost: 9694.299318383788\n",
            "params: [21.72108535 16.89140861]\n",
            "--------------------------\n",
            "iteration: 99\n",
            "cost: 9692.854034511136\n",
            "params: [21.74804736 16.89097007]\n"
          ]
        }
      ],
      "source": [
        "# Do not change the code in this cell\n",
        "# Training the model\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(input_var, output_var, test_size=0.20)\n",
        "\n",
        "params_0 = np.array([20.0, 80.0])\n",
        "\n",
        "alpha_batch = 1e-3\n",
        "max_iter = 100\n",
        "params_hat_batch, cost_batch, params_store_batch =\\\n",
        "    linear_regression_using_batch_gradient_descent(x_train, y_train, params_0, alpha_batch, max_iter)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assigning the cost_batch variable to bgd_costs for clarity."
      ],
      "metadata": {
        "id": "SIUUwCqJqopv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bgd_costs = cost_batch"
      ],
      "metadata": {
        "id": "rAL638lTp1Gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gMza9CnVG6y"
      },
      "source": [
        "### Q2.2 Implement Stochastic Gradient Descent from scratch. (15 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEIJL-WGkq_I"
      },
      "source": [
        "### Stochastic Gradient Descent\n",
        "Algorithm can be given as follows:\n",
        "```shuffle(x, y)\n",
        "for i in 0 -> m:\n",
        "    theta += (alpha / m) * (y[i] - h(x[i])) * x_bar  \n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ordinarily, I would have expected to loop for some configured number of iterations, each time selecting a random example from the training data on which to perform gradient descent, but I was advised in office hours that since the train/test split is already a random sample, we can simply loop over our training data, so that's what I did here.\n"
      ],
      "metadata": {
        "id": "qONMEFnLPMA2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gx9LN0wQkq_I"
      },
      "outputs": [],
      "source": [
        "def lin_reg_stoch_gradient_descent(ip, op, params, alpha):\n",
        "    \"\"\"\n",
        "    Compute the params for linear regression using stochastic gradient descent\n",
        "    ip: input variables\n",
        "    op: output variables\n",
        "    params: corresponding parameters\n",
        "    alpha: learning rate\n",
        "    Returns parameters, cost, params_store\n",
        "    \"\"\"\n",
        "    # input_var and output_var are global vars\n",
        "    # and are being used instead of the method args\n",
        "    # which have been appropriately split.  Assigning\n",
        "    # those values to input_var and output_var to correct.\n",
        "    input_var = ip\n",
        "    output_var = op \n",
        "    # initialize iteration, number of samples, cost and parameter array\n",
        "    num_samples = len(input_var)\n",
        "    cost = np.zeros(num_samples)\n",
        "    params_store = np.zeros([2, num_samples])\n",
        "    \n",
        "    i = 0\n",
        "    # Compute the cost and store the params for the corresponding cost\n",
        "    for x,y in zip(input_var, output_var):\n",
        "        cost[i] = compute_cost(input_var, output_var, params)\n",
        "        params_store[:, i] = params\n",
        "        \n",
        "        print('--------------------------')\n",
        "        print(f'iteration: {i}')\n",
        "        print(f'cost: {cost[i]}')\n",
        "        print(f'params: {params}')\n",
        "        \n",
        "        # Apply stochastic gradient descent\n",
        "        y_hat = np.dot(params, np.array([1.0, x]))\n",
        "        gradient = np.array([1.0, x]) * (y - y_hat)\n",
        "        params += alpha * gradient/num_samples                    \n",
        "\n",
        "        i += 1\n",
        "    return params, cost, params_store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HivE1gVkkq_J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49aa63ba-a0d8-4427-84d4-6d0127bc2b36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------\n",
            "iteration: 0\n",
            "cost: 11910175.085004052\n",
            "params: [20. 80.]\n",
            "--------------------------\n",
            "iteration: 1\n",
            "cost: 10826051.309154604\n",
            "params: [19.95175116 77.05682078]\n",
            "--------------------------\n",
            "iteration: 2\n",
            "cost: 9200477.316152483\n",
            "params: [19.89219045 72.35152444]\n",
            "--------------------------\n",
            "iteration: 3\n",
            "cost: 8317555.639244497\n",
            "params: [19.84883835 69.62034246]\n",
            "--------------------------\n",
            "iteration: 4\n",
            "cost: 8169485.516439803\n",
            "params: [19.83136232 69.14848958]\n",
            "--------------------------\n",
            "iteration: 5\n",
            "cost: 8133031.1952157\n",
            "params: [19.82238141 69.03173774]\n",
            "--------------------------\n",
            "iteration: 6\n",
            "cost: 8132084.029348101\n",
            "params: [19.82087277 69.02872047]\n",
            "--------------------------\n",
            "iteration: 7\n",
            "cost: 7991018.709885463\n",
            "params: [19.80338924 68.57414854]\n",
            "--------------------------\n",
            "iteration: 8\n",
            "cost: 7297499.881769617\n",
            "params: [19.76511562 66.27773157]\n",
            "--------------------------\n",
            "iteration: 9\n",
            "cost: 5634891.849953597\n",
            "params: [19.70452869 60.2796257 ]\n",
            "--------------------------\n",
            "iteration: 10\n",
            "cost: 5616623.116659911\n",
            "params: [19.69865867 60.20918547]\n",
            "--------------------------\n",
            "iteration: 11\n",
            "cost: 5610621.071850444\n",
            "params: [19.69576458 60.18603271]\n",
            "--------------------------\n",
            "iteration: 12\n",
            "cost: 5568310.301877656\n",
            "params: [19.68714624 60.02228434]\n",
            "--------------------------\n",
            "iteration: 13\n",
            "cost: 5390525.503871357\n",
            "params: [19.66783441 59.32705819]\n",
            "--------------------------\n",
            "iteration: 14\n",
            "cost: 4202954.058221621\n",
            "params: [19.61654687 54.3521674 ]\n",
            "--------------------------\n",
            "iteration: 15\n",
            "cost: 4203691.531632111\n",
            "params: [19.61763956 54.35544547]\n",
            "--------------------------\n",
            "iteration: 16\n",
            "cost: 4097983.5078461813\n",
            "params: [19.60324403 53.88039302]\n",
            "--------------------------\n",
            "iteration: 17\n",
            "cost: 4049749.0959068313\n",
            "params: [19.5928275  53.66164587]\n",
            "--------------------------\n",
            "iteration: 18\n",
            "cost: 3763215.8962453296\n",
            "params: [19.56777329 52.33377239]\n",
            "--------------------------\n",
            "iteration: 19\n",
            "cost: 3053802.514215748\n",
            "params: [19.52860799 48.80889565]\n",
            "--------------------------\n",
            "iteration: 20\n",
            "cost: 2990277.5770520433\n",
            "params: [19.51665458 48.47420021]\n",
            "--------------------------\n",
            "iteration: 21\n",
            "cost: 2964277.927826614\n",
            "params: [19.50898954 48.33622941]\n",
            "--------------------------\n",
            "iteration: 22\n",
            "cost: 2407429.7467176383\n",
            "params: [19.4731497  45.21816376]\n",
            "--------------------------\n",
            "iteration: 23\n",
            "cost: 2370420.136767455\n",
            "params: [19.46400849 44.99877472]\n",
            "--------------------------\n",
            "iteration: 24\n",
            "cost: 2351912.163737907\n",
            "params: [19.45849127 44.88843037]\n",
            "--------------------------\n",
            "iteration: 25\n",
            "cost: 2352606.3534730966\n",
            "params: [19.45952477 44.89256434]\n",
            "--------------------------\n",
            "iteration: 26\n",
            "cost: 2334851.444079674\n",
            "params: [19.45469492 44.78630767]\n",
            "--------------------------\n",
            "iteration: 27\n",
            "cost: 2304040.450020587\n",
            "params: [19.44663554 44.60094197]\n",
            "--------------------------\n",
            "iteration: 28\n",
            "cost: 2301756.2446970725\n",
            "params: [19.44434124 44.58717618]\n",
            "--------------------------\n",
            "iteration: 29\n",
            "cost: 1843740.1252792738\n",
            "params: [19.41258481 41.66558476]\n",
            "--------------------------\n",
            "iteration: 30\n",
            "cost: 1512011.581857329\n",
            "params: [19.38457959 39.31314591]\n",
            "--------------------------\n",
            "iteration: 31\n",
            "cost: 1199478.8759578294\n",
            "params: [19.35831907 36.84465685]\n",
            "--------------------------\n",
            "iteration: 32\n",
            "cost: 948278.9877222698\n",
            "params: [19.33432387 34.61310351]\n",
            "--------------------------\n",
            "iteration: 33\n",
            "cost: 932977.2688928483\n",
            "params: [19.32964521 34.46806499]\n",
            "--------------------------\n",
            "iteration: 34\n",
            "cost: 761585.1557130804\n",
            "params: [19.30969783 32.75259044]\n",
            "--------------------------\n",
            "iteration: 35\n",
            "cost: 715022.5820896358\n",
            "params: [19.29930134 32.25355901]\n",
            "--------------------------\n",
            "iteration: 36\n",
            "cost: 644803.1707634099\n",
            "params: [19.28664163 31.46865713]\n",
            "--------------------------\n",
            "iteration: 37\n",
            "cost: 542350.9422012013\n",
            "params: [19.27184884 30.24085546]\n",
            "--------------------------\n",
            "iteration: 38\n",
            "cost: 518714.2987159061\n",
            "params: [19.26471549 29.94125489]\n",
            "--------------------------\n",
            "iteration: 39\n",
            "cost: 489591.3220482181\n",
            "params: [19.25742885 29.56234921]\n",
            "--------------------------\n",
            "iteration: 40\n",
            "cost: 479590.2879573627\n",
            "params: [19.25363623 29.42960769]\n",
            "--------------------------\n",
            "iteration: 41\n",
            "cost: 433585.5970628746\n",
            "params: [19.24379596 28.79983019]\n",
            "--------------------------\n",
            "iteration: 42\n",
            "cost: 420180.51369624643\n",
            "params: [19.23880007 28.60998647]\n",
            "--------------------------\n",
            "iteration: 43\n",
            "cost: 364086.0759133698\n",
            "params: [19.22757813 27.77956312]\n",
            "--------------------------\n",
            "iteration: 44\n",
            "cost: 308909.6610084226\n",
            "params: [19.21652981 26.89569765]\n",
            "--------------------------\n",
            "iteration: 45\n",
            "cost: 304939.852590795\n",
            "params: [19.21423322 26.82909646]\n",
            "--------------------------\n",
            "iteration: 46\n",
            "cost: 291773.6624598622\n",
            "params: [19.20848485 26.60490995]\n",
            "--------------------------\n",
            "iteration: 47\n",
            "cost: 273958.93464894046\n",
            "params: [19.2022474 26.2930374]\n",
            "--------------------------\n",
            "iteration: 48\n",
            "cost: 269650.7961945889\n",
            "params: [19.19916884 26.21607351]\n",
            "--------------------------\n",
            "iteration: 49\n",
            "cost: 247370.58808580093\n",
            "params: [19.19315734 25.80729161]\n",
            "--------------------------\n",
            "iteration: 50\n",
            "cost: 221623.61280261067\n",
            "params: [19.18562599 25.31022243]\n",
            "--------------------------\n",
            "iteration: 51\n",
            "cost: 221760.9100540508\n",
            "params: [19.18831597 25.3129124 ]\n",
            "--------------------------\n",
            "iteration: 52\n",
            "cost: 206782.25866385738\n",
            "params: [19.18280584 25.00985564]\n",
            "--------------------------\n",
            "iteration: 53\n",
            "cost: 202891.14228300427\n",
            "params: [19.18062783 24.9292691 ]\n",
            "--------------------------\n",
            "iteration: 54\n",
            "cost: 181477.64576885116\n",
            "params: [19.17356815 24.4703903 ]\n",
            "--------------------------\n",
            "iteration: 55\n",
            "cost: 160481.5582438691\n",
            "params: [19.16701087 23.99170878]\n",
            "--------------------------\n",
            "iteration: 56\n",
            "cost: 121120.95359206018\n",
            "params: [19.15661761 22.99395546]\n",
            "--------------------------\n",
            "iteration: 57\n",
            "cost: 110604.32653075217\n",
            "params: [19.15233479 22.69844073]\n",
            "--------------------------\n",
            "iteration: 58\n",
            "cost: 110605.63393625563\n",
            "params: [19.15501871 22.69844073]\n",
            "--------------------------\n",
            "iteration: 59\n",
            "cost: 85993.64991451833\n",
            "params: [19.14639621 21.93966063]\n",
            "--------------------------\n",
            "iteration: 60\n",
            "cost: 86488.68939063218\n",
            "params: [19.14873228 21.95601309]\n",
            "--------------------------\n",
            "iteration: 61\n",
            "cost: 78336.60966025412\n",
            "params: [19.14459955 21.67912066]\n",
            "--------------------------\n",
            "iteration: 62\n",
            "cost: 78057.42726409514\n",
            "params: [19.14371258 21.669364  ]\n",
            "--------------------------\n",
            "iteration: 63\n",
            "cost: 77828.39774705637\n",
            "params: [19.14282184 21.66134734]\n",
            "--------------------------\n",
            "iteration: 64\n",
            "cost: 73539.75965678206\n",
            "params: [19.13970191 21.50847043]\n",
            "--------------------------\n",
            "iteration: 65\n",
            "cost: 74309.61957975307\n",
            "params: [19.14168722 21.53626482]\n",
            "--------------------------\n",
            "iteration: 66\n",
            "cost: 70187.43834404336\n",
            "params: [19.1391289  21.38532403]\n",
            "--------------------------\n",
            "iteration: 67\n",
            "cost: 66639.42985111401\n",
            "params: [19.1362759  21.25123309]\n",
            "--------------------------\n",
            "iteration: 68\n",
            "cost: 65657.94009063745\n",
            "params: [19.13543529 21.21340529]\n",
            "--------------------------\n",
            "iteration: 69\n",
            "cost: 61341.91840601645\n",
            "params: [19.13239166 21.04296211]\n",
            "--------------------------\n",
            "iteration: 70\n",
            "cost: 56844.24811373094\n",
            "params: [19.12895831 20.85756152]\n",
            "--------------------------\n",
            "iteration: 71\n",
            "cost: 51734.41774257424\n",
            "params: [19.12604025 20.63578892]\n",
            "--------------------------\n",
            "iteration: 72\n",
            "cost: 48734.222746116095\n",
            "params: [19.12307195 20.49924693]\n",
            "--------------------------\n",
            "iteration: 73\n",
            "cost: 44099.71432312212\n",
            "params: [19.11924887 20.27750805]\n",
            "--------------------------\n",
            "iteration: 74\n",
            "cost: 43008.29719351898\n",
            "params: [19.11743707 20.2231542 ]\n",
            "--------------------------\n",
            "iteration: 75\n",
            "cost: 42536.76963266339\n",
            "params: [19.11697113 20.19939106]\n",
            "--------------------------\n",
            "iteration: 76\n",
            "cost: 36532.75363840992\n",
            "params: [19.11271677 19.8803146 ]\n",
            "--------------------------\n",
            "iteration: 77\n",
            "cost: 36721.390692388944\n",
            "params: [19.11482011 19.89083127]\n",
            "--------------------------\n",
            "iteration: 78\n",
            "cost: 36948.28011603883\n",
            "params: [19.11566155 19.90345285]\n",
            "--------------------------\n",
            "iteration: 79\n",
            "cost: 36708.666635268644\n",
            "params: [19.11526928 19.89011564]\n"
          ]
        }
      ],
      "source": [
        "# Do not change the code in this cell\n",
        "alpha = 1e-3\n",
        "params_0 = np.array([20.0, 80.0])\n",
        "params_hat, cost, params_store =\\\n",
        "lin_reg_stoch_gradient_descent(x_train, y_train, params_0, alpha)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assigning cost to a new variable sgd_cost for clarity."
      ],
      "metadata": {
        "id": "HTr2JeAPq8nM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sgd_costs = cost"
      ],
      "metadata": {
        "id": "2xAt15hurQpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KM0q_avVG60"
      },
      "source": [
        "### Q2.3 Calculate Root Mean Square error in batch gradient descent algorithm and stochastic gradient descent algorithm (5 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNgU_6Q0VG60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec015fc4-41b6-4ba6-8ab8-eb88dd44ef10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BGD RMSE: 359.1913660839094\n",
            "SGD RMSE: 1457.0497466556374\n"
          ]
        }
      ],
      "source": [
        "# Calculate Root Mean Square error in batch gradient descent algorithm and stochastic gradient descent algorithm\n",
        "bgd_rmse = np.sqrt(bgd_costs.sum()/len(bgd_costs))\n",
        "sgd_rmse = np.sqrt(sgd_costs.sum()/len(sgd_costs))\n",
        "\n",
        "print(f\"BGD RMSE: {bgd_rmse}\")\n",
        "print(f\"SGD RMSE: {sgd_rmse}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "930loAL6kq_L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "outputId": "93455620-a6d7-435b-b297-2d9fb9dd7f22"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "min cost with BGD: 9692.854034511136\n",
            "min cost with SGD: 36532.75363840992\n"
          ]
        }
      ],
      "source": [
        "# Do not change the code in this cell\n",
        "plt.figure()\n",
        "plt.plot(np.arange(max_iter), cost_batch, 'r', label='batch')\n",
        "plt.plot(np.arange(len(cost)), cost, 'g', label='stochastic')\n",
        "plt.xlabel('iteration')\n",
        "plt.ylabel('normalized cost')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "print(f'min cost with BGD: {np.min(cost_batch)}')\n",
        "print(f'min cost with SGD: {np.min(cost)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lrpju6Kwkq_N"
      },
      "source": [
        "### Q2.4 Which linear regression model do you think works best for this data? Explain in brief. (5 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgbTux39kq_N"
      },
      "source": [
        "The data obtained in these exercises shows that BGD performs much better on this dataset, and that makes intuitive sense, given that we are calculating the gradient based on each example every iteration, instead of just the one random one in SGD.\n",
        "\n",
        "That said, I was a bit surprised at just how much worse SGD performed in this instance. I believe the results would be much less skewed if the dataset were quite a bit larger and we had more iterations. In that instance, SGD would become more attractive for performance reasons as well, though my reading tells me we should prefer a minibatch version of SGD."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_p02LYZrkq_N"
      },
      "source": [
        "### Q3. Linear Regression Analytical Problem (10 points)\n",
        "Consider the following training data.\n",
        "\n",
        "| X1 | X2 | Y |\n",
        "| -- | -- | -- |\n",
        "| 0 | 0 | 0 |\n",
        "| 0 | 1 | 1.5 |\n",
        "| 1 | 0 | 2 |\n",
        "| 1 | 1 | 2.5 |\n",
        "Suppose the data comes from a model y = $_{0}$ +$_{1}$x1 +$_{2}$x2 for unknown constants $_{0}$,$_{1}$,$_{2}$. Use least squares linear regression to find an estimate of $_{0}$,$_{1}$,$_{2}$."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a straightforward problem for np.linalg.solve.  We just need to set up the appropriate design matrix (including 1s for bias) and y vector."
      ],
      "metadata": {
        "id": "9yfx56Irt93M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([[1, 0, 0],\n",
        "              [1, 0, 1],\n",
        "              [1, 1, 0],\n",
        "              [1, 1, 1]])\n",
        "\n",
        "y = np.array([0, 1.5, 2, 2.5])\n",
        "\n",
        "XTX = np.dot(X.T,X)\n",
        "XTy = np.dot(X.T, y)\n",
        "\n",
        "weights = np.linalg.solve(XTX, XTy)\n",
        "print(f\"Theta0 = {weights[0]}, Theta1 = {weights[1]}, Theta2 = {weights[2]} \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiYGyt43J9zW",
        "outputId": "6a6c5e21-a02c-4f01-f4aa-c2c159b4796b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Theta0 = 0.25, Theta1 = 1.5, Theta2 = 1.0 \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "ML_HW1_DecisionTreesAndRegression.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}