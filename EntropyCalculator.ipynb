{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EntropyCalculator.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPxzQ8yB0jxGPI4+Mi1kPhr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/c-daly/Notebooks/blob/main/EntropyCalculator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook is a educational project to better understand entropy and decision trees as described in Chapter 14 of Norvig and Russel's AIMA.  "
      ],
      "metadata": {
        "id": "EhoctCUiEMz2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "label_column = 'willwait'\n",
        "\n",
        "example1 = {'alt': 'yes', 'bar': 'no', 'frisat': 'no', 'hungry': 'yes', 'patrons': 'some', 'price': '3', 'rain': 'no', 'res': 'yes', 'type': 'french', 'wait': '10', 'willwait': 'yes'  }\n",
        "example2 = {'alt': 'yes', 'bar': 'no', 'frisat': 'no', 'hungry': 'yes', 'patrons': 'full', 'price': '1', 'rain': 'no', 'res': 'no', 'type': 'thai', 'wait': '60', 'willwait': 'no'  }\n",
        "example3 = {'alt': 'no', 'bar': 'yes', 'frisat': 'no', 'hungry': 'no', 'patrons': 'some', 'price': '1', 'rain': 'no', 'res': 'no', 'type': 'burger', 'wait': '10', 'willwait': 'yes'  }\n",
        "example4 = {'alt': 'yes', 'bar': 'no', 'frisat': 'yes', 'hungry': 'yes', 'patrons': 'full', 'price': '1', 'rain': 'yes', 'res': 'no', 'type': 'thai', 'wait': '30', 'willwait': 'yes'  }\n",
        "example5 = {'alt': 'yes', 'bar': 'no', 'frisat': 'yes', 'hungry': 'no', 'patrons': 'full', 'price': '3', 'rain': 'no', 'res': 'yes', 'type': 'french', 'wait': '61', 'willwait': 'no'  }\n",
        "example6 = {'alt': 'no', 'bar': 'yes', 'frisat': 'no', 'hungry': 'yes', 'patrons': 'some', 'price': '2', 'rain': 'yes', 'res': 'yes', 'type': 'italian', 'wait': '10', 'willwait': 'yes'  }\n",
        "example7 = {'alt': 'no', 'bar': 'yes', 'frisat': 'no', 'hungry': 'no', 'patrons': 'none', 'price': '1', 'rain': 'yes', 'res': 'no', 'type': 'burger', 'wait': '10', 'willwait': 'no'  }\n",
        "example8 = {'alt': 'no', 'bar': 'no', 'frisat': 'no', 'hungry': 'yes', 'patrons': 'some', 'price': '2', 'rain': 'yes', 'res': 'yes', 'type': 'thai', 'wait': '10', 'willwait': 'yes'  }\n",
        "example9 = {'alt': 'no', 'bar': 'yes', 'frisat': 'yes', 'hungry': 'no', 'patrons': 'full', 'price': '1', 'rain': 'yes', 'res': 'no', 'type': 'burger', 'wait': '61', 'willwait': 'no'  }\n",
        "example10 = {'alt': 'yes', 'bar': 'yes', 'frisat': 'yes', 'hungry': 'yes', 'patrons': 'full', 'price': '3', 'rain': 'no', 'res': 'yes', 'type': 'italian', 'wait': '30', 'willwait': 'no' }\n",
        "example11 = {'alt': 'no', 'bar': 'no', 'frisat': 'no', 'hungry': 'no', 'patrons': 'none', 'price': '1', 'rain': 'no', 'res': 'no', 'type': 'thai', 'wait': '10', 'willwait': 'no'  }\n",
        "example12 = {'alt': 'yes', 'bar': 'yes', 'frisat': 'yes', 'hungry': 'yes', 'patrons': 'full', 'price': '1', 'rain': 'no', 'res': 'no', 'type': 'burger', 'wait': '60', 'willwait': 'yes' }\n",
        "\n",
        "data = [\n",
        "  example1, example2, example3, example4, example5, example6, example7, example8, example9, example10, example11, example12\n",
        "] \n",
        "\n",
        "df = pd.DataFrame.from_records(data)\n"
      ],
      "metadata": {
        "id": "rij0IkyQEnAQ"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Node:\n",
        "  def __init__(self, parent, attribute):\n",
        "    self.parent = parent\n",
        "    self.children = {}\n",
        "    self.attribute = attribute"
      ],
      "metadata": {
        "id": "pb2kE5EdEm53"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def allExamplesHaveSameClassification(examples):\n",
        "   return len(set(examples[label_column])) == 1\n",
        "\n",
        "\n",
        "def getPluralityValue(examples):\n",
        "  num_positives = len(getPositiveValues(examples))\n",
        "\n",
        "  if num_positives > len(examples) - num_positives:\n",
        "    return 'yes'\n",
        "  else:\n",
        "    return 'no'\n",
        "\n",
        "def getPositiveValues(examples):\n",
        "  positive_examples = df[df[label_column] == 'yes']\n",
        "  #print(f\"Positive examples: {positive_examples}\")\n",
        "  return positive_examples\n",
        "\n",
        "def getNumPositiveExamplesByAttributeValue(examples, attribute, value):\n",
        "  #print(f\"{feature},{value}\")\n",
        "  positive_examples = examples[(examples[attribute] == value) & (examples[label_column] == 'yes')]\n",
        "  #print(f\"Positive examples: {positive_examples}\")\n",
        "  return len(positive_examples)\n",
        "\n",
        "def B(prob):\n",
        "  #print(f\"prob: {np.log2(prob)}\")\n",
        "  if prob == 0:\n",
        "    result = 0\n",
        "  else:\n",
        "    firstLogResult = 0\n",
        "    secondLogResult = 0\n",
        "    if prob > 0:\n",
        "      firstLogResult = np.log2(prob)\n",
        "    if prob < 1:\n",
        "      secondLogResult = np.log2(1-prob)\n",
        "    result = -(prob * firstLogResult + (1-prob) * secondLogResult)\n",
        "  #print(f\"B result: {result}\")\n",
        "  return result\n",
        "\n",
        "def remainder(examples, attribute, values):\n",
        "  remainder = 0\n",
        "  total_count = len(examples)\n",
        "  total_positive = len(examples[examples[label_column] == 'yes'])\n",
        "  value_positive_count = 0\n",
        "  value_negative_count = 0\n",
        "  for value in values:\n",
        "    #print(f\"in value loop for value, attribute: {value},{attribute}\")\n",
        "    value_count = len(df[df[attribute] == value])\n",
        "    value_positive_count = getNumPositiveExamplesByAttributeValue(examples, attribute, value)\n",
        "    #print(f\"value count/total: {value_count}/{total_count}\")\n",
        "    #print(f\"{attribute}.{value}: value positive count/value count: {value_positive_count}/{value_count}\")\n",
        "    #print(f\"prob arg: {value_positive_count/value_count}\")\n",
        "    temp = (value_count/total_count) * B(value_positive_count/value_count)\n",
        "    #print(f\"temp result: {temp}\")\n",
        "    remainder += temp\n",
        "\n",
        "  #print(f\"total value positive count: {value_positive_count}\")\n",
        "  #print(f\"{attribute}: remainder: {remainder}\")\n",
        "  return remainder\n",
        "\n",
        "def calculateEntropy(examples, feature, values):\n",
        "\n",
        "  probabilities = []\n",
        "\n",
        "  for value in values:\n",
        "    #print(f\"in value loop for value, feature: {value},{feature}\")\n",
        "    num_positives = getNumPositiveExamplesByFeatureValue(examples, feature, value)\n",
        "    num_negatives = len(examples) - num_positives\n",
        "\n",
        "  prob_positive = num_positives / len(examples)\n",
        "  #print(f\"prob_positive: {prob_positive}\")\n",
        "  entropy = -(prob_positive * np.log2(prob_positive))\n",
        "  return entropy\n",
        "\n",
        "def calculateGainForAttribute(examples, attribute, values):\n",
        "  total_count = len(examples)\n",
        "  total_positive = len(getPositiveValues(examples))\n",
        "\n",
        "  b = B(total_positive/total_count)\n",
        "  result = b - remainder(examples, attribute, values) \n",
        "  print(f\"{attribute} gain: {result}\")\n",
        "  return result\n",
        "\n",
        "def getAttributesFromExamples(examples):\n",
        "  if len(examples) == 0:\n",
        "    return None\n",
        "  else:\n",
        "    return [key for key in examples[0].keys() if key != label_column]\n",
        "\n",
        "def getAttributeValuesFromExamples(examples, attribute):\n",
        "  if len(examples) == 0:\n",
        "    return None\n",
        "  else:\n",
        "    #return set([example[attribute] for example in examples])\n",
        "    return examples[attribute].unique()\n",
        "\n",
        "def getMostImportantAttribute(examples):\n",
        "  gain = 0\n",
        "  best_attribute = None\n",
        "  attributes = examples.columns #getAttributesFromExamples(examples)\n",
        "  for attribute in attributes:\n",
        "    if attribute == label_column:\n",
        "      continue\n",
        "    #getAttributeValuesFromExamples(examples, attribute)\n",
        "    temp_gain = calculateGainForAttribute(examples, attribute, getAttributeValuesFromExamples(examples, attribute))\n",
        "    if temp_gain > gain:\n",
        "      gain = temp_gain\n",
        "      best_attribute = attribute\n",
        "  print(f\"Attribute/gain: {best_attribute}/{gain}\")\n",
        "  return best_attribute\n"
      ],
      "metadata": {
        "id": "Y_bDkoOnAMW4"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def learnDecisionTree(features, examples, parent_examples):\n",
        "  if not examples.values.any():\n",
        "    return getPluralityValue(parent_examples)\n",
        "  elif allExamplesHaveSameClassification(examples):\n",
        "    print(examples[label_column])\n",
        "    return examples[label_column].first()\n",
        "  elif not features.any():\n",
        "    return getPluralityValue(examples)\n",
        "  else:\n",
        "    attribute = getMostImportantAttribute(examples)\n",
        "    if attribute is None:\n",
        "      return\n",
        "    node = Node(None, attribute)\n",
        "    print(attribute)\n",
        "    values = examples[attribute].unique()\n",
        "    if values.any():\n",
        "      for value in values:\n",
        "        value_examples = examples.loc[examples[attribute] == value]\n",
        "        #child = learnDecisionTree(features, value_examples, examples)\n",
        "learnDecisionTree(df.columns, df, None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXccz_YgCsqD",
        "outputId": "6b7f106f-ca29-446f-b422-c925ae247351"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alt gain: 0.0\n",
            "bar gain: 0.0\n",
            "frisat gain: 0.020720839623908027\n",
            "hungry gain: 0.19570962879973086\n",
            "patrons gain: 0.5408520829727552\n",
            "price gain: 0.19570962879973086\n",
            "rain gain: 0.020720839623908027\n",
            "res gain: 0.020720839623908027\n",
            "type gain: 1.1102230246251565e-16\n",
            "wait gain: 0.20751874963942196\n",
            "Attribute/gain: patrons/0.5408520829727552\n",
            "patrons\n"
          ]
        }
      ]
    }
  ]
}